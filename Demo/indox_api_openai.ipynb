{
 "cells": [
  {
   "metadata": {
    "id": "a0b4b137e4479438"
   },
   "cell_type": "markdown",
   "source": [
    "## Indox Retrieval Augmentation\n",
    "Here, we will explore how to work with Indox Retrieval Augmentation. We are using OpenAI from Indox Api, we should set our INDOX_OPENAI_API_KEY as an environment variable.\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/osllmai/inDox/blob/master/Demo/indox_api_openai.ipynb)"
   ],
   "id": "a0b4b137e4479438"
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install indox\n",
    "!pip install chromadb"
   ],
   "metadata": {
    "id": "fxYANSd_d72e",
    "outputId": "000fba73-6465-4760-cb04-658971cd555d",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "id": "fxYANSd_d72e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Setting Up the Python Environment\n",
    "\n",
    "If you are running this project in your local IDE, please create a Python environment to ensure all dependencies are correctly managed. You can follow the steps below to set up a virtual environment named `indox`:\n",
    "\n",
    "### Windows\n",
    "\n",
    "1. **Create the virtual environment:**\n",
    "```bash\n",
    "  python -m venv indox\n",
    "```\n",
    "\n",
    "2. **Activate the virtual environment:**\n",
    "```bash\n",
    "  indox\\Scripts\\activate\n",
    "```\n",
    "\n",
    "\n",
    "### macOS/Linux\n",
    "\n",
    "1. **Create the virtual environment:**\n",
    "   ```bash\n",
    "   python3 -m venv indox\n",
    "   \n",
    "2. **Activate the virtual environment:**\n",
    "```bash\n",
    "  source indox/bin/activate\n",
    "```\n",
    "\n",
    "### Install Dependencies\n",
    "\n",
    "Once the virtual environment is activated, install the required dependencies by running:\n",
    "\n",
    "```bash\n",
    "  pip install -r requirements.txt\n",
    "```\n"
   ],
   "id": "2105c4c9997b2e2d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "!wget https://raw.githubusercontent.com/osllmai/inDox/master/Demo/sample.txt",
   "id": "62861510e8ede2ca"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Setting Up the Python Environment\n",
    "\n",
    "If you are running this project in your local IDE, please create a Python environment to ensure all dependencies are correctly managed. You can follow the steps below to set up a virtual environment named `indox`:\n",
    "\n",
    "### Windows\n",
    "\n",
    "1. **Create the virtual environment:**\n",
    "```bash\n",
    "python -m venv indox\n",
    "```\n",
    "2. **Activate the virtual environment:**\n",
    "```bash\n",
    "indox_judge\\Scripts\\activate\n",
    "```\n",
    "\n",
    "### macOS/Linux\n",
    "\n",
    "1. **Create the virtual environment:**\n",
    "   ```bash\n",
    "   python3 -m venv indox\n",
    "```\n",
    "\n",
    "2. **Activate the virtual environment:**\n",
    "    ```bash\n",
    "   source indox/bin/activate\n",
    "```\n",
    "### Install Dependencies\n",
    "\n",
    "Once the virtual environment is activated, install the required dependencies by running:\n",
    "\n",
    "```bash\n",
    "pip install -r requirements.txt\n",
    "```\n"
   ],
   "id": "d6f36bae5e61e743"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "id": "initial_id",
    "ExecuteTime": {
     "end_time": "2024-07-24T05:30:56.863773Z",
     "start_time": "2024-07-24T05:30:56.851364Z"
    }
   },
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "INDOX_API_KEY= os.getenv(\"INDOX_API_KEY\")"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "id": "fc1dbe21e3fa2f2e"
   },
   "cell_type": "markdown",
   "source": [
    "### Creating an instance of IndoxTetrivalAugmentation\n",
    "\n",
    "To effectively utilize the Indox Retrieval Augmentation capabilities, you must first create an instance of the IndoxRetrievalAugmentation class. This instance will allow you to access the methods and properties defined within the class, enabling the augmentation and retrieval functionalities."
   ],
   "id": "fc1dbe21e3fa2f2e"
  },
  {
   "metadata": {
    "id": "482156866f7df32c",
    "ExecuteTime": {
     "end_time": "2024-07-24T05:30:59.022114Z",
     "start_time": "2024-07-24T05:30:58.852225Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from indox import IndoxRetrievalAugmentation\n",
    "indox = IndoxRetrievalAugmentation()"
   ],
   "id": "482156866f7df32c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[32mINFO\u001B[0m: \u001B[1mIndoxRetrievalAugmentation initialized\u001B[0m\n",
      "\n",
      "            ██  ███    ██  ██████   ██████  ██       ██\n",
      "            ██  ████   ██  ██   ██ ██    ██   ██  ██\n",
      "            ██  ██ ██  ██  ██   ██ ██    ██     ██\n",
      "            ██  ██  ██ ██  ██   ██ ██    ██   ██   ██\n",
      "            ██  ██  █████  ██████   ██████  ██       ██\n",
      "            \n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "id": "8c7d82fa001f121"
   },
   "cell_type": "markdown",
   "source": [
    "### Generating response using Indox\n",
    "IndoxApi class is used to handle question-answering task using Indox model. This instance creates IndoxOpenAIEmbedding class to specifying embedding model.By using ClusteredSplit function we can import pdf and text file and split them into chunks."
   ],
   "id": "8c7d82fa001f121"
  },
  {
   "metadata": {
    "id": "5840d601bf111608",
    "outputId": "34a39efd-1e37-478a-83c7-a7c1b255805b",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "ExecuteTime": {
     "end_time": "2024-07-24T05:33:00.058510Z",
     "start_time": "2024-07-24T05:31:06.876402Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Import necessary classes from Indox library\n",
    "from indox.llms import IndoxApi\n",
    "from indox.embeddings import IndoxApiEmbedding\n",
    "from indox.data_loader_splitter import ClusteredSplit\n",
    "\n",
    "# Create instances for API access and text embedding\n",
    "openai_qa_indox = IndoxApi(api_key=INDOX_API_KEY)\n",
    "embed_openai_indox = IndoxApiEmbedding(api_key=INDOX_API_KEY, model=\"text-embedding-3-small\")\n",
    "\n",
    "# Specify the path to your text file\n",
    "file_path = \"sample.txt\"\n",
    "\n",
    "# Create a ClusteredSplit instance for handling file loading and chunking\n",
    "loader_splitter = ClusteredSplit(file_path=file_path, embeddings=embed_openai_indox, summary_model=openai_qa_indox)\n",
    "\n",
    "# Load and split the document into chunks using ClusteredSplit\n",
    "docs = loader_splitter.load_and_chunk()"
   ],
   "id": "5840d601bf111608",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[32mINFO\u001B[0m: \u001B[1mInitialized IndoxOpenAIEmbedding with model: text-embedding-3-small\u001B[0m\n",
      "\u001B[32mINFO\u001B[0m: \u001B[1mClusteredSplit initialized successfully\u001B[0m\n",
      "\u001B[32mINFO\u001B[0m: \u001B[1mStarting processing for documents\u001B[0m\n",
      "\u001B[32mINFO\u001B[0m: \u001B[1mEmbedding documents\u001B[0m\n",
      "\u001B[32mINFO\u001B[0m: \u001B[1mStarting to fetch embeddings texts using engine: text-embedding-3-small\u001B[0m\n",
      "\u001B[32mINFO\u001B[0m: \u001B[1m--Generated 7 clusters--\u001B[0m\n",
      "\u001B[32mINFO\u001B[0m: \u001B[1mEmbedding documents\u001B[0m\n",
      "\u001B[32mINFO\u001B[0m: \u001B[1mStarting to fetch embeddings texts using engine: text-embedding-3-small\u001B[0m\n",
      "\u001B[32mINFO\u001B[0m: \u001B[1m--Generated 1 clusters--\u001B[0m\n",
      "\u001B[32mINFO\u001B[0m: \u001B[1mCompleted chunking & clustering process\u001B[0m\n",
      "\u001B[32mINFO\u001B[0m: \u001B[1mSuccessfully obtained all documents\u001B[0m\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "source": [
    "docs[2]"
   ],
   "metadata": {
    "id": "XVXR7NPhetnb",
    "outputId": "9c64ff3a-c9cd-4dc7-c48e-c233fe5b711d",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "ExecuteTime": {
     "end_time": "2024-07-24T05:33:04.387804Z",
     "start_time": "2024-07-24T05:33:04.383939Z"
    }
   },
   "id": "XVXR7NPhetnb",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'  They took her pretty clothes away from her, put an old grey bedgown on her, and gave her wooden shoes   Just look at the proud princess, how decked out she is, they cried, and laughed, and led her into the kitchen There she had to do hard work from morning till night, get up before daybreak, carry water, light fires, cook and wash   Besides this, the sisters did her every imaginable injury - they mocked her'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "id": "8ad8ffb82df90153"
   },
   "cell_type": "markdown",
   "source": [
    " Here ChromaVectorStore handles the storage and retrieval of vector embeddings by specifying a collection name and sets up a vector store where text embeddings can be stored and queried."
   ],
   "id": "8ad8ffb82df90153"
  },
  {
   "metadata": {
    "id": "72d8e01f62f1f4d",
    "outputId": "422e7f26-4a2f-40dd-9d88-cb1e356b3477",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "ExecuteTime": {
     "end_time": "2024-07-24T05:33:14.527207Z",
     "start_time": "2024-07-24T05:33:14.371330Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from indox.vector_stores import Chroma\n",
    "\n",
    "# Define the collection name within the vector store\n",
    "collection_name = \"sample\"\n",
    "\n",
    "# Create a ChromaVectorStore instance\n",
    "db = Chroma(collection_name=collection_name, embedding_function=embed_openai_indox)\n",
    "\n",
    "# Connect to the vector store using the provided database instance\n",
    "indox.connect_to_vectorstore(vectorstore_database=db)"
   ],
   "id": "72d8e01f62f1f4d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[32mINFO\u001B[0m: \u001B[1mConnection to the vector store database established successfully\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<indox.vector_stores.chroma.Chroma at 0x1f34da28b90>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "id": "e84c43974ab6c990"
   },
   "cell_type": "markdown",
   "source": [
    "### load and preprocess data\n",
    "This part of code demonstrates how to load and preprocess text data from a file, split it into chunks, and store these chunks in the vector store that was set up previously."
   ],
   "id": "e84c43974ab6c990"
  },
  {
   "metadata": {
    "id": "78a775a8daa69372",
    "outputId": "9b927bf5-d3c4-4ad8-a1c0-b3711e67775e",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "ExecuteTime": {
     "end_time": "2024-07-24T05:34:23.429924Z",
     "start_time": "2024-07-24T05:33:16.398907Z"
    }
   },
   "cell_type": "code",
   "source": [
    "indox.store_in_vectorstore(docs=docs)"
   ],
   "id": "78a775a8daa69372",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[32mINFO\u001B[0m: \u001B[1mStoring documents in the vector store\u001B[0m\n",
      "\u001B[32mINFO\u001B[0m: \u001B[1mEmbedding documents\u001B[0m\n",
      "\u001B[32mINFO\u001B[0m: \u001B[1mStarting to fetch embeddings texts using engine: text-embedding-3-small\u001B[0m\n",
      "\u001B[32mINFO\u001B[0m: \u001B[1mDocument added successfully to the vector store.\u001B[0m\n",
      "\u001B[32mINFO\u001B[0m: \u001B[1mDocuments stored successfully\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<indox.vector_stores.chroma.Chroma at 0x1f34da28b90>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "id": "3c7ddb297b70e98d"
   },
   "cell_type": "markdown",
   "source": [
    "### Retrieve relevant information and generate an answer\n",
    "The main purpose of these lines is to perform a query on the vector store to retrieve the most relevant information (top_k=5) and generate an answer using the language model."
   ],
   "id": "3c7ddb297b70e98d"
  },
  {
   "metadata": {
    "id": "5eeddd295be41564",
    "ExecuteTime": {
     "end_time": "2024-07-24T05:34:26.416103Z",
     "start_time": "2024-07-24T05:34:26.412646Z"
    }
   },
   "cell_type": "code",
   "source": [
    "query = \"How cinderella reach her happy ending?\"\n",
    "retriever = indox.QuestionAnswer(vector_database=db,llm=openai_qa_indox,top_k=5)"
   ],
   "id": "5eeddd295be41564",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "id": "197a0067afd5532e"
   },
   "cell_type": "markdown",
   "source": [
    "invoke(query) method sends the query to the retriever, which searches the vector store for relevant text chunks and uses the language model to generate a response based on the retrieved information.\n",
    "Context property retrieves the context or the detailed information that the retriever used to generate the answer to the query. It provides insight into how the query was answered by showing the relevant text chunks and any additional information used."
   ],
   "id": "197a0067afd5532e"
  },
  {
   "metadata": {
    "id": "eb95a1c3fcdba812",
    "outputId": "028463e5-4552-484b-9337-0d7ecb9d924a",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "ExecuteTime": {
     "end_time": "2024-07-24T05:34:34.805479Z",
     "start_time": "2024-07-24T05:34:29.715543Z"
    }
   },
   "cell_type": "code",
   "source": [
    "retriever.invoke(query)"
   ],
   "id": "eb95a1c3fcdba812",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[32mINFO\u001B[0m: \u001B[1mRetrieving context and scores from the vector database\u001B[0m\n",
      "\u001B[32mINFO\u001B[0m: \u001B[1mEmbedding documents\u001B[0m\n",
      "\u001B[32mINFO\u001B[0m: \u001B[1mStarting to fetch embeddings texts using engine: text-embedding-3-small\u001B[0m\n",
      "\u001B[32mINFO\u001B[0m: \u001B[1mGenerating answer without document relevancy filter\u001B[0m\n",
      "\u001B[32mINFO\u001B[0m: \u001B[1mQuery answered successfully\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Cinderella reaches her happy ending in the classic fairy tale by fitting perfectly into the golden slipper that only the true bride can wear. Despite the attempts of her stepsisters to deceive the prince by cutting off parts of their toes and heels to fit into the slipper, it is Cinderella who ultimately proves her identity by fitting into the shoe perfectly. The prince recognizes her as the one he danced with at the ball, and they ride off together, leaving the false brides behind. This moment of recognition and acceptance by the prince leads Cinderella to her happily ever after, where true love prevails in the end.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "id": "a2d500d6244768cb",
    "outputId": "2de11787-ee0b-4be5-caeb-556edab1bcbb",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "ExecuteTime": {
     "end_time": "2024-07-24T05:34:36.575204Z",
     "start_time": "2024-07-24T05:34:36.570126Z"
    }
   },
   "cell_type": "code",
   "source": [
    "retriever.context"
   ],
   "id": "a2d500d6244768cb",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The provided documentation is a retelling of the classic fairy tale \"Cinderella.\" It describes the story of a young maiden who is mistreated by her stepmother and stepsisters but ultimately finds her happily ever after with the prince. The story revolves around a golden slipper that only fits the true bride, leading to the stepsisters trying to force their feet into the shoe by cutting off parts of their toes and heels. However, it is only Cinderella who fits perfectly into the slipper, revealing her true identity to the prince. The prince recognizes her as the one he danced with at the ball and they ride off together, leaving the false brides behind. The story highlights themes of kindness, perseverance, and true love prevailing in the end.',\n",
       " \"The documentation provided consists of a retelling of the classic fairy tale of Cinderella. It begins with the wife of a rich man passing away and advising her daughter to be good and pious. After her death, the daughter visits her mother's grave regularly and remains kind-hearted. However, when winter comes, the man remarries a woman with two daughters who mistreat the step-daughter. The step-daughter is relegated to the role of a kitchen-wench and is mocked by her step-sisters. Despite her hardships, Cinderella remains resilient and kind.\\n\\nThe story progresses with Cinderella attending a festival by the help of a little hazel tree and a bird. She is able to attend the festival in a beautiful dress but must return before\",\n",
       " \"The provided documentation consists of a retelling of the classic fairy tale of Cinderella. It begins with the wife of a rich man passing away and advising her daughter to be good and pious. After her death, the daughter visits her mother's grave regularly and remains kind-hearted. However, when winter comes, the man remarries a woman with two daughters who mistreat the step-daughter.\\n\\nThe step-daughter is relegated to the role of a kitchen-wench and is mocked by her step-sisters. Despite her hardships, Cinderella remains resilient and kind. The story progresses with Cinderella attending a festival by the help of a little hazel tree and a bird. She is able to attend the festival in a beautiful dress but must return to\",\n",
       " \"The documentation provided is a collection of excerpts from the story of Cinderella. It describes how Cinderella is mistreated by her stepmother and stepsisters, who force her to do hard work and treat her poorly. Despite her difficult circumstances, Cinderella remains kind and hopeful. The story highlights Cinderella's resilience and eventual transformation, as she overcomes her challenges and finds happiness. The excerpts also touch upon Cinderella's desire to attend a festival and her interactions with her stepmother and stepsisters. Overall, the story of Cinderella is a classic tale of perseverance, kindness, and ultimately, triumph over adversity.\",\n",
       " \"The documentation provided is a collection of excerpts from the fairy tale of Cinderella. It begins with Cinderella's father asking his two step-daughters what gifts he should bring back for them. The step-daughters ask for beautiful dresses, pearls, and jewels, while Cinderella asks for the first branch that knocks against his hat on his way home. The father fulfills the wishes of the step-daughters but also brings back a hazel twig for Cinderella.\\n\\nThe story then progresses to describe how Cinderella goes to a hazel tree to weep and pray, where a little white bird fulfills her wishes. When a royal festival is announced, Cinderella's step-sisters prepare to attend, and Cinderella helps them get ready while wishing\"]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "id": "6ec341bb6534cd4f"
   },
   "cell_type": "markdown",
   "source": [
    "### With AgenticRag\n",
    "\n",
    "AgenticRag stands for Agentic Retrieval-Augmented Generation. This concept combines retrieval-based methods and generation-based methods in natural language processing (NLP). The key idea is to enhance the generative capabilities of a language model by incorporating relevant information retrieved from a database or a vector store.\n",
    " AgenticRag is designed to provide more contextually rich and accurate responses by utilizing external knowledge sources. It retrieves relevant pieces of information (chunks) from a vector store based on a query and then uses a language model to generate a comprehensive response that incorporates this retrieved information."
   ],
   "id": "6ec341bb6534cd4f"
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install duckduckgo_search"
   ],
   "metadata": {
    "id": "IPb0wAj3f1WI",
    "outputId": "a8aa17a2-35af-42fb-8de4-91d54377b343",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "ExecuteTime": {
     "end_time": "2024-07-09T15:43:49.603564Z",
     "start_time": "2024-07-09T15:43:47.013911Z"
    }
   },
   "id": "IPb0wAj3f1WI",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-09 19:13:47,307 INFO:Backing off send_request(...) for 0.7s (requests.exceptions.SSLError: HTTPSConnectionPool(host='us-api.i.posthog.com', port=443): Max retries exceeded with url: /batch/ (Caused by SSLError(SSLError(1, '[SSL: WRONG_VERSION_NUMBER] wrong version number (_ssl.c:1000)'))))\n",
      "2024-07-09 19:13:49,053 ERROR:Giving up send_request(...) after 4 tries (requests.exceptions.SSLError: HTTPSConnectionPool(host='us-api.i.posthog.com', port=443): Max retries exceeded with url: /batch/ (Caused by SSLError(SSLError(1, '[SSL: WRONG_VERSION_NUMBER] wrong version number (_ssl.c:1000)'))))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: duckduckgo_search in c:\\users\\ashkan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (6.1.6)\n",
      "Requirement already satisfied: click>=8.1.7 in c:\\users\\ashkan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from duckduckgo_search) (8.1.7)\n",
      "Requirement already satisfied: pyreqwest-impersonate>=0.4.7 in c:\\users\\ashkan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from duckduckgo_search) (0.4.7)\n",
      "Requirement already satisfied: orjson>=3.10.4 in c:\\users\\ashkan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from duckduckgo_search) (3.10.5)\n",
      "Requirement already satisfied: colorama in c:\\users\\ashkan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from click>=8.1.7->duckduckgo_search) (0.4.6)\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-22T16:39:36.157519Z",
     "start_time": "2024-06-22T16:39:15.367500Z"
    },
    "id": "bf2dd2fbe3a7a74a",
    "outputId": "0520585f-7436-466d-8ef8-46d2bf8f916d",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 174
    }
   },
   "cell_type": "code",
   "source": [
    "agent = indox.AgenticRag(llm=openai_qa_indox,vector_database=db,top_k=5)\n",
    "agent.run(query)"
   ],
   "id": "bf2dd2fbe3a7a74a",
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Relevant doc\n",
      "Relevant doc\n",
      "Relevant doc\n",
      "Relevant doc\n",
      "Relevant doc\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "\"Cinderella reaches her happy ending by attending the royal festival with the help of magical elements such as a hazel tree, birds, and a golden slipper. Despite being mistreated by her stepmother and stepsisters, Cinderella's true identity is revealed with the assistance of the magical bird and two white doves. The false stepsisters' deception is exposed, and Cinderella fits perfectly into the golden slipper, proving she is the true bride sought by the prince. As a result, Cinderella marries the king's son and is able to live happily ever after.\""
      ],
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      }
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-22T16:39:59.947779Z",
     "start_time": "2024-06-22T16:39:59.944427Z"
    },
    "id": "ae50b369603a1e2c"
   },
   "cell_type": "code",
   "source": [
    "query_2 = \"where does messi plays right now?\""
   ],
   "id": "ae50b369603a1e2c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-22T16:40:26.380527Z",
     "start_time": "2024-06-22T16:40:03.832586Z"
    },
    "id": "1b16988ccc80dc97",
    "outputId": "8392c752-cea2-4e1a-8d3e-4425c87996c0",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 174
    }
   },
   "cell_type": "code",
   "source": [
    "agent.run(query_2)"
   ],
   "id": "1b16988ccc80dc97",
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Not Relevant doc\n",
      "Not Relevant doc\n",
      "Not Relevant doc\n",
      "Not Relevant doc\n",
      "Not Relevant doc\n",
      "No Relevant Context Found, Start Searching On Web...\n",
      "Answer Base On Web Search\n",
      "Check For Hallucination In Generated Answer Base On Web Search\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'Lionel Messi currently plays for Inter Miami CF in Major League Soccer.'"
      ],
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      }
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "colab": {
   "provenance": []
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

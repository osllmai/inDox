{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b08dd419d6000548",
   "metadata": {},
   "source": [
    "# QdrantDB \n",
    "In this notebook, we will demonstrate how to use QdrantDB, for accessing and querying data efficiently. QdrantDB is designed to work seamlessly with modern analytical workloads, making it a powerful tool for data analysis, research, and question-answering systems.\n",
    "\n",
    "To begin, ensure you have `QdrantDB` installed in your Python environment. You can easily install it using `pip install qdrant-client`.\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/osllmai/inDox/blob/master/cookbook/indoxArcg/qdrant.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "495ab1719e590dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install indoxArcg\n",
    "!pip install qdrant-client\n",
    "!pip install semantic_text_splitter\n",
    "!pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf57a151559ee787",
   "metadata": {},
   "source": [
    "## Setting Up the Python Environment\n",
    "\n",
    "If you are running this project in your local IDE, please create a Python environment to ensure all dependencies are correctly managed. You can follow the steps below to set up a virtual environment named `indoxArcg`:\n",
    "\n",
    "### Windows\n",
    "\n",
    "1. **Create the virtual environment:**\n",
    "```bash\n",
    "python -m venv indoxArcg\n",
    "```\n",
    "2. **Activate the virtual environment:**\n",
    "```bash\n",
    "indoxArcg\\Scripts\\activate\n",
    "```\n",
    "\n",
    "### macOS/Linux\n",
    "\n",
    "1. **Create the virtual environment:**\n",
    "   ```bash\n",
    "   python3 -m venv indoxArcg\n",
    "```\n",
    "\n",
    "2. **Activate the virtual environment:**\n",
    "    ```bash\n",
    "   source indoxArcg/bin/activate\n",
    "```\n",
    "### Install Dependencies\n",
    "\n",
    "Once the virtual environment is activated, install the required dependencies by running:\n",
    "\n",
    "```bash\n",
    "pip install -r requirements.txt\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec2c2a3c62b0792",
   "metadata": {},
   "source": [
    "### Load Hugging face API key And QDRANT API KEY\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c613a99d0ded33aa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-09T11:49:51.644116Z",
     "start_time": "2024-09-09T11:49:51.633935Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv('api.env')\n",
    "\n",
    "HUGGINGFACE_API_KEY = os.environ['HUGGINGFACE_API_KEY']\n",
    "QDRANT_API_KEY = os.environ['Qdrant_API_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0068f71d99b80d6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-09T11:49:58.454605Z",
     "start_time": "2024-09-09T11:49:51.679679Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO\u001b[0m: \u001b[1mInitializing HuggingFaceAPIModel with model: mistralai/Mistral-7B-Instruct-v0.2\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m: \u001b[1mHuggingFaceAPIModel initialized successfully\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m: \u001b[1mInitialized HuggingFaceEmbedding with model: multi-qa-mpnet-base-cos-v1\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from indoxArcg.llms import HuggingFaceAPIModel\n",
    "from indoxArcg.embeddings import HuggingFaceEmbedding\n",
    "mistral_qa = HuggingFaceAPIModel(api_key=HUGGINGFACE_API_KEY,model=\"mistralai/Mistral-7B-Instruct-v0.2\")\n",
    "embed = HuggingFaceEmbedding(api_key=HUGGINGFACE_API_KEY,model=\"multi-qa-mpnet-base-cos-v1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1216d563d5816a9",
   "metadata": {},
   "source": [
    "Initialize a language model and an embedding model using the indox library with Hugging Face . The HuggingFaceAPIModel class is used to create an instance of the Mistral-7B-Instruct model for tasks like question answering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94d69ffa21e3e36",
   "metadata": {},
   "source": [
    "### Load Sample Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9544d8dec6a6c732",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://raw.githubusercontent.com/osllmai/inDox/master/Demo/sample.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "321b0a77e8c6eb2c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-09T11:49:58.538471Z",
     "start_time": "2024-09-09T11:49:58.535841Z"
    }
   },
   "outputs": [],
   "source": [
    "file_path = \"sample.txt\"\n",
    "with open(file_path, \"r\") as file:\n",
    "    text = file.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3c0b68b9743ff84",
   "metadata": {},
   "source": [
    "use the `RecursiveCharacterTextSplitter` class from the indox library to divide a large text into smaller, manageable chunks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77acd5449764c08b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-09T11:49:58.589797Z",
     "start_time": "2024-09-09T11:49:58.583372Z"
    }
   },
   "outputs": [],
   "source": [
    "from indoxArcg.splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "splitter = RecursiveCharacterTextSplitter(400,20)\n",
    "content_chunks = splitter.split_text(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7306ef8819ba6377",
   "metadata": {},
   "source": [
    "### Set up vector store\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1305111b9507318",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-09T11:50:00.263527Z",
     "start_time": "2024-09-09T11:49:58.641108Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO\u001b[0m: \u001b[1mEmbedding documents\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m: \u001b[1mStarting to fetch embeddings for texts using model: SentenceTransformer(\n",
      "  (0): Transformer({'max_seq_length': 512, 'do_lower_case': False}) with Transformer model: MPNetModel \n",
      "  (1): Pooling({'word_embedding_dimension': 768, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
      "  (2): Normalize()\n",
      ")\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  4.81it/s]\n",
      "2024-09-09 15:20:00,259 - httpx - INFO - HTTP Request: PUT https://ffbf001a-09a2-4afc-baa9-6e64584f7d01.europe-west3-0.gcp.cloud.qdrant.io:6333/collections/IndoxTest2 \"HTTP/1.1 409 Conflict\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collection IndoxTest2 already exists.\n"
     ]
    }
   ],
   "source": [
    "from indoxArcg.vector_stores import Qdrant\n",
    "\n",
    "url = \"url\" \n",
    "qdrant = Qdrant(\n",
    "    collection_name=\"IndoxTest\", \n",
    "    embedding_function=embed, \n",
    "    url=url, \n",
    "    api_key=QDRANT_API_KEY\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f6fdd79e293590",
   "metadata": {},
   "source": [
    "### Storing Data in the Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8bdb065ad4d5ae02",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-09T11:50:01.480820Z",
     "start_time": "2024-09-09T11:50:00.284114Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO\u001b[0m: \u001b[1mEmbedding documents\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m: \u001b[1mStarting to fetch embeddings for texts using model: SentenceTransformer(\n",
      "  (0): Transformer({'max_seq_length': 512, 'do_lower_case': False}) with Transformer model: MPNetModel \n",
      "  (1): Pooling({'word_embedding_dimension': 768, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
      "  (2): Normalize()\n",
      ")\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 2/2 [00:00<00:00, 15.16it/s]\n",
      "2024-09-09 15:20:01,469 - httpx - INFO - HTTP Request: PUT https://ffbf001a-09a2-4afc-baa9-6e64584f7d01.europe-west3-0.gcp.cloud.qdrant.io:6333/collections/IndoxTest2/points?wait=true \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['1ea39065-a426-4264-9543-4bf3ca5fe851',\n",
       " '1beb709f-0995-47f7-9292-51e81351ab99',\n",
       " 'fc171713-4323-4e57-9397-99faeb2ed81d',\n",
       " '80d33960-3bee-40e7-a6d9-9a4a3bb6a9c2',\n",
       " 'bb33d4f9-89de-4caa-9c16-95e5400c4bd3',\n",
       " '70799ae2-1fbb-4c77-9ef7-938b43a72d3f',\n",
       " '62697cec-7847-4ab6-a947-d2d08279e5df',\n",
       " 'b166a95c-3133-4cef-b349-b6b6033ae0b4',\n",
       " 'd9fb7b1e-a7b8-41f7-9982-144fab7b558d',\n",
       " '77a572c5-5e8a-4492-be63-1973769a724a',\n",
       " 'c1a9715c-07ab-466e-8cac-0c5e8fb1cabf',\n",
       " '26b1f4ae-72b2-4e47-8d78-96e4176a523e',\n",
       " '98f9b089-4a88-49c2-a593-8dadb3c684e6',\n",
       " 'd50874da-1645-49f3-8359-812249b54857',\n",
       " 'cfe17ac5-8f47-4873-b31c-441b1280aef8',\n",
       " '7f018883-577c-410e-99bd-8fcc25a3d1ef',\n",
       " 'd6c1d9d0-2059-4d06-802f-a115f2edb8b1',\n",
       " 'f72ff63d-1ca3-434c-a085-d09fc0e36188',\n",
       " '161c91b6-32c2-4caf-a769-68c3f4f8f498',\n",
       " 'caa245ce-799b-42ea-ba38-fa4b90fb686f',\n",
       " '5aa14d33-0bdf-4093-8ad1-0d32625acfdb',\n",
       " 'f6d2ac79-0b30-49e3-b564-c7bcdf3e3363',\n",
       " '21db3a5a-3f46-4243-b7ea-f0638afaec0e',\n",
       " '1cd009dc-27d2-4d96-851c-c412b2bc09f2',\n",
       " '3d7f6877-c0f1-4a64-87b8-2e38e05a9de6',\n",
       " '4f5d404d-4feb-450b-816e-52fbf87dc58c',\n",
       " '2e4d2de3-dd47-40cd-bbd6-6b28159a9c34',\n",
       " 'eab501db-072b-48af-bbd3-c472fda8b254',\n",
       " '330722a0-539e-42c5-ae7a-ea0821a90f84',\n",
       " '2462f285-c84f-4e58-bb63-dd43ce3cea9f',\n",
       " '29cead54-2cc6-48de-bc45-48295b663300',\n",
       " 'cae66ff3-13d9-4c4f-a10a-28c8cd445912',\n",
       " 'a59ae972-a06d-4acf-a492-b3c334fb8bfe',\n",
       " 'd37a74b2-7a39-49c8-8eb4-b0ef4851c56f',\n",
       " 'fd0b75eb-1ce9-4ace-80cc-2fc83404d66e',\n",
       " '7f7e148f-291a-4e73-ad7a-00629fb51b12',\n",
       " '17f7f8d4-6b56-412f-9d2f-145807f6b223',\n",
       " 'd24f98cf-9607-4162-8e8b-5768b54de097']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qdrant.add(texts=content_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2fdf5f2534c09447",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-09T11:50:03.820493Z",
     "start_time": "2024-09-09T11:50:01.502086Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO\u001b[0m: \u001b[1mRetrieving context and scores from the vector database\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m: \u001b[1mEmbedding documents\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m: \u001b[1mStarting to fetch embeddings for texts using model: SentenceTransformer(\n",
      "  (0): Transformer({'max_seq_length': 512, 'do_lower_case': False}) with Transformer model: MPNetModel \n",
      "  (1): Pooling({'word_embedding_dimension': 768, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
      "  (2): Normalize()\n",
      ")\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 151.49it/s]\n",
      "2024-09-09 15:20:01,744 - httpx - INFO - HTTP Request: POST https://ffbf001a-09a2-4afc-baa9-6e64584f7d01.europe-west3-0.gcp.cloud.qdrant.io:6333/collections/IndoxTest2/points/search \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO\u001b[0m: \u001b[1mGenerating answer without document relevancy filter\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m: \u001b[1mAnswering question\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m: \u001b[1mSending request to Hugging Face API\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m: \u001b[1mReceived successful response from Hugging Face API\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m: \u001b[1mQuery answered successfully\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "query = \"How cinderella reach her happy ending?\"\n",
    "from indoxArcg.pipelines.rag import RAG\n",
    "retriever = RAG(llm=mistral_qa,vector_store=qdrant,top_k= 5)\n",
    "answer = retriever.infer(query=query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "24d369858ab7365d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-09T11:50:30.037484Z",
     "start_time": "2024-09-09T11:50:30.034787Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Cinderella receives a magical gift from a bird, allowing her to attend a royal ball where she catches the eye of the prince. When the prince realizes that his new bride is actually Cinderella, he takes her away on his horse to live happily ever after, leaving her cruel step-mother and step-sisters behind in regret and anger.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MarkitDown",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

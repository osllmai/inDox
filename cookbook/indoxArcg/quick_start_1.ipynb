{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "7e95779738aca6f6",
      "metadata": {
        "id": "7e95779738aca6f6"
      },
      "source": [
        "# Quick Start"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f24e01441be4b95",
      "metadata": {
        "id": "f24e01441be4b95"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/osllmai/inDox/blob/master/cookbook/indoxArcg/quick_start.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "c5b69401",
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "import os\n",
        "module_path = os.path.abspath('D:/osllm/inDox/libs/indoxArcg')\n",
        "if module_path not in sys.path:\n",
        "    sys.path.append(module_path)\n",
        "    print(\"module path added to sys.path\")\n",
        "    \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2e19065cca32a590",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2e19065cca32a590",
        "outputId": "824cd089-7cb6-4b0e-b2dc-dfe43a9706f3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting indoxArcg\n",
            "  Downloading indoxArcg-0.0.4-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting latex2markdown (from indoxArcg)\n",
            "  Downloading latex2markdown-0.2.1.tar.gz (161 kB)\n",
            "  Preparing metadata (setup.py): started\n",
            "  Preparing metadata (setup.py): finished with status 'done'\n",
            "Collecting loguru (from indoxArcg)\n",
            "  Downloading loguru-0.7.3-py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: numpy in c:\\users\\nemat\\.conda\\envs\\markitdown\\lib\\site-packages (from indoxArcg) (2.2.1)\n",
            "Requirement already satisfied: pandas in c:\\users\\nemat\\.conda\\envs\\markitdown\\lib\\site-packages (from indoxArcg) (2.2.3)\n",
            "Collecting protobuf (from indoxArcg)\n",
            "  Downloading protobuf-6.30.1-cp310-abi3-win_amd64.whl.metadata (593 bytes)\n",
            "Requirement already satisfied: pydantic in c:\\users\\nemat\\.conda\\envs\\markitdown\\lib\\site-packages (from indoxArcg) (2.10.4)\n",
            "Collecting PyPDF2 (from indoxArcg)\n",
            "  Downloading pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting python-dotenv (from indoxArcg)\n",
            "  Using cached python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: Requests in c:\\users\\nemat\\.conda\\envs\\markitdown\\lib\\site-packages (from indoxArcg) (2.32.3)\n",
            "Requirement already satisfied: setuptools in c:\\users\\nemat\\.conda\\envs\\markitdown\\lib\\site-packages (from indoxArcg) (75.6.0)\n",
            "Collecting tenacity (from indoxArcg)\n",
            "  Using cached tenacity-9.0.0-py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: tiktoken in c:\\users\\nemat\\.conda\\envs\\markitdown\\lib\\site-packages (from indoxArcg) (0.8.0)\n",
            "Collecting tokenizers (from indoxArcg)\n",
            "  Downloading tokenizers-0.21.1-cp39-abi3-win_amd64.whl.metadata (6.9 kB)\n",
            "Collecting umap_learn (from indoxArcg)\n",
            "  Using cached umap_learn-0.5.7-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting unstructured (from indoxArcg)\n",
            "  Downloading unstructured-0.17.0-py3-none-any.whl.metadata (24 kB)\n",
            "Collecting nltk (from indoxArcg)\n",
            "  Using cached nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting pillow_heif (from indoxArcg)\n",
            "  Downloading pillow_heif-0.22.0-cp310-cp310-win_amd64.whl.metadata (9.8 kB)\n",
            "Collecting rank_bm25 (from indoxArcg)\n",
            "  Downloading rank_bm25-0.2.2-py3-none-any.whl.metadata (3.2 kB)\n",
            "Requirement already satisfied: colorama>=0.3.4 in c:\\users\\nemat\\.conda\\envs\\markitdown\\lib\\site-packages (from loguru->indoxArcg) (0.4.6)\n",
            "Collecting win32-setctime>=1.0.0 (from loguru->indoxArcg)\n",
            "  Downloading win32_setctime-1.2.0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting click (from nltk->indoxArcg)\n",
            "  Downloading click-8.1.8-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting joblib (from nltk->indoxArcg)\n",
            "  Using cached joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
            "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\nemat\\.conda\\envs\\markitdown\\lib\\site-packages (from nltk->indoxArcg) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in c:\\users\\nemat\\.conda\\envs\\markitdown\\lib\\site-packages (from nltk->indoxArcg) (4.67.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\nemat\\.conda\\envs\\markitdown\\lib\\site-packages (from pandas->indoxArcg) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\users\\nemat\\.conda\\envs\\markitdown\\lib\\site-packages (from pandas->indoxArcg) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\nemat\\.conda\\envs\\markitdown\\lib\\site-packages (from pandas->indoxArcg) (2024.2)\n",
            "Requirement already satisfied: pillow>=10.1.0 in c:\\users\\nemat\\.conda\\envs\\markitdown\\lib\\site-packages (from pillow_heif->indoxArcg) (11.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\nemat\\.conda\\envs\\markitdown\\lib\\site-packages (from pydantic->indoxArcg) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in c:\\users\\nemat\\.conda\\envs\\markitdown\\lib\\site-packages (from pydantic->indoxArcg) (2.27.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in c:\\users\\nemat\\.conda\\envs\\markitdown\\lib\\site-packages (from pydantic->indoxArcg) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\nemat\\.conda\\envs\\markitdown\\lib\\site-packages (from Requests->indoxArcg) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\nemat\\.conda\\envs\\markitdown\\lib\\site-packages (from Requests->indoxArcg) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\nemat\\.conda\\envs\\markitdown\\lib\\site-packages (from Requests->indoxArcg) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\nemat\\.conda\\envs\\markitdown\\lib\\site-packages (from Requests->indoxArcg) (2024.12.14)\n",
            "Collecting huggingface-hub<1.0,>=0.16.4 (from tokenizers->indoxArcg)\n",
            "  Downloading huggingface_hub-0.29.3-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting scipy>=1.3.1 (from umap_learn->indoxArcg)\n",
            "  Downloading scipy-1.15.2-cp310-cp310-win_amd64.whl.metadata (60 kB)\n",
            "Collecting scikit-learn>=0.22 (from umap_learn->indoxArcg)\n",
            "  Downloading scikit_learn-1.6.1-cp310-cp310-win_amd64.whl.metadata (15 kB)\n",
            "Collecting numba>=0.51.2 (from umap_learn->indoxArcg)\n",
            "  Downloading numba-0.61.0-cp310-cp310-win_amd64.whl.metadata (2.8 kB)\n",
            "Collecting pynndescent>=0.5 (from umap_learn->indoxArcg)\n",
            "  Using cached pynndescent-0.5.13-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting chardet (from unstructured->indoxArcg)\n",
            "  Downloading chardet-5.2.0-py3-none-any.whl.metadata (3.4 kB)\n",
            "Collecting filetype (from unstructured->indoxArcg)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting python-magic (from unstructured->indoxArcg)\n",
            "  Downloading python_magic-0.4.27-py2.py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: lxml in c:\\users\\nemat\\.conda\\envs\\markitdown\\lib\\site-packages (from unstructured->indoxArcg) (5.3.0)\n",
            "Requirement already satisfied: beautifulsoup4 in c:\\users\\nemat\\.conda\\envs\\markitdown\\lib\\site-packages (from unstructured->indoxArcg) (4.12.3)\n",
            "Collecting emoji (from unstructured->indoxArcg)\n",
            "  Downloading emoji-2.14.1-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting dataclasses-json (from unstructured->indoxArcg)\n",
            "  Using cached dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting python-iso639 (from unstructured->indoxArcg)\n",
            "  Downloading python_iso639-2025.2.18-py3-none-any.whl.metadata (14 kB)\n",
            "Collecting langdetect (from unstructured->indoxArcg)\n",
            "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
            "     ---------------------------------------- 0.0/981.5 kB ? eta -:--:--\n",
            "     ------------------------------------- 981.5/981.5 kB 15.3 MB/s eta 0:00:00\n",
            "  Preparing metadata (setup.py): started\n",
            "  Preparing metadata (setup.py): finished with status 'done'\n",
            "Collecting numpy (from indoxArcg)\n",
            "  Using cached numpy-1.26.4-cp310-cp310-win_amd64.whl.metadata (61 kB)\n",
            "Collecting rapidfuzz (from unstructured->indoxArcg)\n",
            "  Downloading rapidfuzz-3.12.2-cp310-cp310-win_amd64.whl.metadata (12 kB)\n",
            "Collecting backoff (from unstructured->indoxArcg)\n",
            "  Using cached backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
            "Collecting unstructured-client (from unstructured->indoxArcg)\n",
            "  Downloading unstructured_client-0.31.1-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting wrapt (from unstructured->indoxArcg)\n",
            "  Downloading wrapt-1.17.2-cp310-cp310-win_amd64.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: psutil in c:\\users\\nemat\\.conda\\envs\\markitdown\\lib\\site-packages (from unstructured->indoxArcg) (6.1.1)\n",
            "Collecting python-oxmsg (from unstructured->indoxArcg)\n",
            "  Downloading python_oxmsg-0.0.2-py3-none-any.whl.metadata (5.0 kB)\n",
            "Collecting html5lib (from unstructured->indoxArcg)\n",
            "  Downloading html5lib-1.1-py2.py3-none-any.whl.metadata (16 kB)\n",
            "Collecting filelock (from huggingface-hub<1.0,>=0.16.4->tokenizers->indoxArcg)\n",
            "  Downloading filelock-3.18.0-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting fsspec>=2023.5.0 (from huggingface-hub<1.0,>=0.16.4->tokenizers->indoxArcg)\n",
            "  Downloading fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: packaging>=20.9 in c:\\users\\nemat\\.conda\\envs\\markitdown\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->indoxArcg) (24.2)\n",
            "Collecting pyyaml>=5.1 (from huggingface-hub<1.0,>=0.16.4->tokenizers->indoxArcg)\n",
            "  Downloading PyYAML-6.0.2-cp310-cp310-win_amd64.whl.metadata (2.1 kB)\n",
            "Collecting llvmlite<0.45,>=0.44.0dev0 (from numba>=0.51.2->umap_learn->indoxArcg)\n",
            "  Downloading llvmlite-0.44.0-cp310-cp310-win_amd64.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\nemat\\.conda\\envs\\markitdown\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->indoxArcg) (1.17.0)\n",
            "Collecting threadpoolctl>=3.1.0 (from scikit-learn>=0.22->umap_learn->indoxArcg)\n",
            "  Downloading threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: soupsieve>1.2 in c:\\users\\nemat\\.conda\\envs\\markitdown\\lib\\site-packages (from beautifulsoup4->unstructured->indoxArcg) (2.6)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json->unstructured->indoxArcg)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json->unstructured->indoxArcg)\n",
            "  Using cached typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting webencodings (from html5lib->unstructured->indoxArcg)\n",
            "  Using cached webencodings-0.5.1-py2.py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting olefile (from python-oxmsg->unstructured->indoxArcg)\n",
            "  Downloading olefile-0.47-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting aiofiles>=24.1.0 (from unstructured-client->unstructured->indoxArcg)\n",
            "  Downloading aiofiles-24.1.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: cryptography>=3.1 in c:\\users\\nemat\\.conda\\envs\\markitdown\\lib\\site-packages (from unstructured-client->unstructured->indoxArcg) (44.0.0)\n",
            "Collecting eval-type-backport>=0.2.0 (from unstructured-client->unstructured->indoxArcg)\n",
            "  Downloading eval_type_backport-0.2.2-py3-none-any.whl.metadata (2.2 kB)\n",
            "Requirement already satisfied: httpx>=0.27.0 in c:\\users\\nemat\\.conda\\envs\\markitdown\\lib\\site-packages (from unstructured-client->unstructured->indoxArcg) (0.28.1)\n",
            "Requirement already satisfied: nest-asyncio>=1.6.0 in c:\\users\\nemat\\.conda\\envs\\markitdown\\lib\\site-packages (from unstructured-client->unstructured->indoxArcg) (1.6.0)\n",
            "Collecting pypdf>=4.0 (from unstructured-client->unstructured->indoxArcg)\n",
            "  Downloading pypdf-5.4.0-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting requests-toolbelt>=1.0.0 (from unstructured-client->unstructured->indoxArcg)\n",
            "  Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
            "Collecting typing-inspection>=0.4.0 (from unstructured-client->unstructured->indoxArcg)\n",
            "  Downloading typing_inspection-0.4.0-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: cffi>=1.12 in c:\\users\\nemat\\.conda\\envs\\markitdown\\lib\\site-packages (from cryptography>=3.1->unstructured-client->unstructured->indoxArcg) (1.17.1)\n",
            "Requirement already satisfied: anyio in c:\\users\\nemat\\.conda\\envs\\markitdown\\lib\\site-packages (from httpx>=0.27.0->unstructured-client->unstructured->indoxArcg) (4.7.0)\n",
            "Requirement already satisfied: httpcore==1.* in c:\\users\\nemat\\.conda\\envs\\markitdown\\lib\\site-packages (from httpx>=0.27.0->unstructured-client->unstructured->indoxArcg) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\nemat\\.conda\\envs\\markitdown\\lib\\site-packages (from httpcore==1.*->httpx>=0.27.0->unstructured-client->unstructured->indoxArcg) (0.14.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json->unstructured->indoxArcg)\n",
            "  Using cached mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: pycparser in c:\\users\\nemat\\.conda\\envs\\markitdown\\lib\\site-packages (from cffi>=1.12->cryptography>=3.1->unstructured-client->unstructured->indoxArcg) (2.22)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\nemat\\.conda\\envs\\markitdown\\lib\\site-packages (from anyio->httpx>=0.27.0->unstructured-client->unstructured->indoxArcg) (1.2.2)\n",
            "Requirement already satisfied: sniffio>=1.1 in c:\\users\\nemat\\.conda\\envs\\markitdown\\lib\\site-packages (from anyio->httpx>=0.27.0->unstructured-client->unstructured->indoxArcg) (1.3.1)\n",
            "Downloading indoxArcg-0.0.4-py3-none-any.whl (220 kB)\n",
            "Downloading loguru-0.7.3-py3-none-any.whl (61 kB)\n",
            "Using cached nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
            "Downloading pillow_heif-0.22.0-cp310-cp310-win_amd64.whl (8.6 MB)\n",
            "   ---------------------------------------- 0.0/8.6 MB ? eta -:--:--\n",
            "   -------------------------- ------------- 5.8/8.6 MB 27.1 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 8.6/8.6 MB 21.2 MB/s eta 0:00:00\n",
            "Downloading protobuf-6.30.1-cp310-abi3-win_amd64.whl (431 kB)\n",
            "Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
            "Using cached python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading rank_bm25-0.2.2-py3-none-any.whl (8.6 kB)\n",
            "Using cached tenacity-9.0.0-py3-none-any.whl (28 kB)\n",
            "Downloading tokenizers-0.21.1-cp39-abi3-win_amd64.whl (2.4 MB)\n",
            "   ---------------------------------------- 0.0/2.4 MB ? eta -:--:--\n",
            "   ---------------------------------------- 2.4/2.4 MB 27.9 MB/s eta 0:00:00\n",
            "Using cached umap_learn-0.5.7-py3-none-any.whl (88 kB)\n",
            "Downloading unstructured-0.17.0-py3-none-any.whl (1.8 MB)\n",
            "   ---------------------------------------- 0.0/1.8 MB ? eta -:--:--\n",
            "   ---------------------------------------- 1.8/1.8 MB 24.3 MB/s eta 0:00:00\n",
            "Using cached numpy-1.26.4-cp310-cp310-win_amd64.whl (15.8 MB)\n",
            "Downloading huggingface_hub-0.29.3-py3-none-any.whl (468 kB)\n",
            "Downloading numba-0.61.0-cp310-cp310-win_amd64.whl (2.8 MB)\n",
            "   ---------------------------------------- 0.0/2.8 MB ? eta -:--:--\n",
            "   ---------------------------------------- 2.8/2.8 MB 32.5 MB/s eta 0:00:00\n",
            "Using cached pynndescent-0.5.13-py3-none-any.whl (56 kB)\n",
            "Using cached joblib-1.4.2-py3-none-any.whl (301 kB)\n",
            "Downloading scikit_learn-1.6.1-cp310-cp310-win_amd64.whl (11.1 MB)\n",
            "   ---------------------------------------- 0.0/11.1 MB ? eta -:--:--\n",
            "   ---------------------------------------  11.0/11.1 MB 52.9 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 11.1/11.1 MB 30.3 MB/s eta 0:00:00\n",
            "Downloading scipy-1.15.2-cp310-cp310-win_amd64.whl (41.2 MB)\n",
            "   ---------------------------------------- 0.0/41.2 MB ? eta -:--:--\n",
            "   --------- ------------------------------ 10.2/41.2 MB 53.3 MB/s eta 0:00:01\n",
            "   -------------------- ------------------- 21.5/41.2 MB 50.3 MB/s eta 0:00:01\n",
            "   ------------------------------- -------- 32.8/41.2 MB 52.0 MB/s eta 0:00:01\n",
            "   ---------------------------------------  41.2/41.2 MB 50.4 MB/s eta 0:00:01\n",
            "   ---------------------------------------  41.2/41.2 MB 50.4 MB/s eta 0:00:01\n",
            "   ---------------------------------------  41.2/41.2 MB 50.4 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 41.2/41.2 MB 30.9 MB/s eta 0:00:00\n",
            "Downloading win32_setctime-1.2.0-py3-none-any.whl (4.1 kB)\n",
            "Using cached backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading chardet-5.2.0-py3-none-any.whl (199 kB)\n",
            "Downloading click-8.1.8-py3-none-any.whl (98 kB)\n",
            "Using cached dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading emoji-2.14.1-py3-none-any.whl (590 kB)\n",
            "   ---------------------------------------- 0.0/590.6 kB ? eta -:--:--\n",
            "   --------------------------------------- 590.6/590.6 kB 21.9 MB/s eta 0:00:00\n",
            "Downloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Downloading html5lib-1.1-py2.py3-none-any.whl (112 kB)\n",
            "Downloading python_iso639-2025.2.18-py3-none-any.whl (167 kB)\n",
            "Downloading python_magic-0.4.27-py2.py3-none-any.whl (13 kB)\n",
            "Downloading python_oxmsg-0.0.2-py3-none-any.whl (31 kB)\n",
            "Downloading rapidfuzz-3.12.2-cp310-cp310-win_amd64.whl (1.6 MB)\n",
            "   ---------------------------------------- 0.0/1.6 MB ? eta -:--:--\n",
            "   ---------------------------------------- 1.6/1.6 MB 22.0 MB/s eta 0:00:00\n",
            "Downloading unstructured_client-0.31.1-py3-none-any.whl (166 kB)\n",
            "Downloading wrapt-1.17.2-cp310-cp310-win_amd64.whl (38 kB)\n",
            "Downloading aiofiles-24.1.0-py3-none-any.whl (15 kB)\n",
            "Downloading eval_type_backport-0.2.2-py3-none-any.whl (5.8 kB)\n",
            "Downloading fsspec-2025.3.0-py3-none-any.whl (193 kB)\n",
            "Downloading llvmlite-0.44.0-cp310-cp310-win_amd64.whl (30.3 MB)\n",
            "   ---------------------------------------- 0.0/30.3 MB ? eta -:--:--\n",
            "   -------- ------------------------------- 6.8/30.3 MB 34.9 MB/s eta 0:00:01\n",
            "   ------------------- -------------------- 14.9/30.3 MB 36.2 MB/s eta 0:00:01\n",
            "   --------------------------------- ------ 25.2/30.3 MB 40.8 MB/s eta 0:00:01\n",
            "   ---------------------------------------  30.1/30.3 MB 41.6 MB/s eta 0:00:01\n",
            "   ---------------------------------------  30.1/30.3 MB 41.6 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 30.3/30.3 MB 27.5 MB/s eta 0:00:00\n",
            "Downloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "Downloading pypdf-5.4.0-py3-none-any.whl (302 kB)\n",
            "Downloading PyYAML-6.0.2-cp310-cp310-win_amd64.whl (161 kB)\n",
            "Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
            "Downloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
            "Using cached typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading typing_inspection-0.4.0-py3-none-any.whl (14 kB)\n",
            "Downloading filelock-3.18.0-py3-none-any.whl (16 kB)\n",
            "Downloading olefile-0.47-py2.py3-none-any.whl (114 kB)\n",
            "Using cached webencodings-0.5.1-py2.py3-none-any.whl (11 kB)\n",
            "Using cached mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Building wheels for collected packages: latex2markdown, langdetect\n",
            "  Building wheel for latex2markdown (setup.py): started\n",
            "  Building wheel for latex2markdown (setup.py): finished with status 'done'\n",
            "  Created wheel for latex2markdown: filename=latex2markdown-0.2.1-py3-none-any.whl size=9017 sha256=7bfc3eb7bb2d7ed8edc3b997a367deba068f83cef5458bf1b37ee5e9d31bdf8a\n",
            "  Stored in directory: c:\\users\\nemat\\appdata\\local\\pip\\cache\\wheels\\48\\d0\\8a\\5009532cfcf3a270e1126c6a46d73ab028737188faf768fbba\n",
            "  Building wheel for langdetect (setup.py): started\n",
            "  Building wheel for langdetect (setup.py): finished with status 'done'\n",
            "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993251 sha256=5bb74306c696acae3a3a587972574de8f7f9f5bfc38aa16409379657db6e0e07\n",
            "  Stored in directory: c:\\users\\nemat\\appdata\\local\\pip\\cache\\wheels\\95\\03\\7d\\59ea870c70ce4e5a370638b5462a7711ab78fba2f655d05106\n",
            "Successfully built latex2markdown langdetect\n",
            "Installing collected packages: webencodings, latex2markdown, filetype, wrapt, win32-setctime, typing-inspection, threadpoolctl, tenacity, rapidfuzz, pyyaml, python-magic, python-iso639, python-dotenv, PyPDF2, pypdf, protobuf, pillow_heif, olefile, numpy, mypy-extensions, marshmallow, llvmlite, langdetect, joblib, html5lib, fsspec, filelock, eval-type-backport, emoji, click, chardet, backoff, aiofiles, typing-inspect, scipy, requests-toolbelt, rank_bm25, python-oxmsg, numba, nltk, loguru, huggingface-hub, unstructured-client, tokenizers, scikit-learn, dataclasses-json, unstructured, pynndescent, umap_learn, indoxArcg\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.2.1\n",
            "    Uninstalling numpy-2.2.1:\n",
            "      Successfully uninstalled numpy-2.2.1\n",
            "Successfully installed PyPDF2-3.0.1 aiofiles-24.1.0 backoff-2.2.1 chardet-5.2.0 click-8.1.8 dataclasses-json-0.6.7 emoji-2.14.1 eval-type-backport-0.2.2 filelock-3.18.0 filetype-1.2.0 fsspec-2025.3.0 html5lib-1.1 huggingface-hub-0.29.3 indoxArcg-0.0.4 joblib-1.4.2 langdetect-1.0.9 latex2markdown-0.2.1 llvmlite-0.44.0 loguru-0.7.3 marshmallow-3.26.1 mypy-extensions-1.0.0 nltk-3.9.1 numba-0.61.0 numpy-1.26.4 olefile-0.47 pillow_heif-0.22.0 protobuf-6.30.1 pynndescent-0.5.13 pypdf-5.4.0 python-dotenv-1.0.1 python-iso639-2025.2.18 python-magic-0.4.27 python-oxmsg-0.0.2 pyyaml-6.0.2 rank_bm25-0.2.2 rapidfuzz-3.12.2 requests-toolbelt-1.0.0 scikit-learn-1.6.1 scipy-1.15.2 tenacity-9.0.0 threadpoolctl-3.6.0 tokenizers-0.21.1 typing-inspect-0.9.0 typing-inspection-0.4.0 umap_learn-0.5.7 unstructured-0.17.0 unstructured-client-0.31.1 webencodings-0.5.1 win32-setctime-1.2.0 wrapt-1.17.2\n",
            "Requirement already satisfied: openai in c:\\users\\nemat\\.conda\\envs\\markitdown\\lib\\site-packages (1.58.1)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\nemat\\.conda\\envs\\markitdown\\lib\\site-packages (from openai) (4.7.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\nemat\\.conda\\envs\\markitdown\\lib\\site-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\nemat\\.conda\\envs\\markitdown\\lib\\site-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\nemat\\.conda\\envs\\markitdown\\lib\\site-packages (from openai) (0.8.2)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\nemat\\.conda\\envs\\markitdown\\lib\\site-packages (from openai) (2.10.4)\n",
            "Requirement already satisfied: sniffio in c:\\users\\nemat\\.conda\\envs\\markitdown\\lib\\site-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in c:\\users\\nemat\\.conda\\envs\\markitdown\\lib\\site-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\users\\nemat\\.conda\\envs\\markitdown\\lib\\site-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\nemat\\.conda\\envs\\markitdown\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
            "Requirement already satisfied: idna>=2.8 in c:\\users\\nemat\\.conda\\envs\\markitdown\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in c:\\users\\nemat\\.conda\\envs\\markitdown\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2024.12.14)\n",
            "Requirement already satisfied: httpcore==1.* in c:\\users\\nemat\\.conda\\envs\\markitdown\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\nemat\\.conda\\envs\\markitdown\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\nemat\\.conda\\envs\\markitdown\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in c:\\users\\nemat\\.conda\\envs\\markitdown\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (2.27.2)\n",
            "Requirement already satisfied: colorama in c:\\users\\nemat\\.conda\\envs\\markitdown\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n",
            "Collecting chromadb\n",
            "  Downloading chromadb-0.6.3-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting build>=1.0.3 (from chromadb)\n",
            "  Downloading build-1.2.2.post1-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: pydantic>=1.9 in c:\\users\\nemat\\.conda\\envs\\markitdown\\lib\\site-packages (from chromadb) (2.10.4)\n",
            "Collecting chroma-hnswlib==0.7.6 (from chromadb)\n",
            "  Using cached chroma_hnswlib-0.7.6-cp310-cp310-win_amd64.whl.metadata (262 bytes)\n",
            "Collecting fastapi>=0.95.2 (from chromadb)\n",
            "  Downloading fastapi-0.115.11-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting uvicorn>=0.18.3 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading uvicorn-0.34.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: numpy>=1.22.5 in c:\\users\\nemat\\.conda\\envs\\markitdown\\lib\\site-packages (from chromadb) (1.26.4)\n",
            "Collecting posthog>=2.4.0 (from chromadb)\n",
            "  Downloading posthog-3.21.0-py2.py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in c:\\users\\nemat\\.conda\\envs\\markitdown\\lib\\site-packages (from chromadb) (4.12.2)\n",
            "Collecting onnxruntime>=1.14.1 (from chromadb)\n",
            "  Downloading onnxruntime-1.21.0-cp310-cp310-win_amd64.whl.metadata (4.9 kB)\n",
            "Collecting opentelemetry-api>=1.2.0 (from chromadb)\n",
            "  Downloading opentelemetry_api-1.31.0-py3-none-any.whl.metadata (1.6 kB)\n",
            "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.31.0-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb)\n",
            "  Downloading opentelemetry_instrumentation_fastapi-0.52b0-py3-none-any.whl.metadata (2.2 kB)\n",
            "Collecting opentelemetry-sdk>=1.2.0 (from chromadb)\n",
            "  Downloading opentelemetry_sdk-1.31.0-py3-none-any.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in c:\\users\\nemat\\.conda\\envs\\markitdown\\lib\\site-packages (from chromadb) (0.21.1)\n",
            "Collecting pypika>=0.48.9 (from chromadb)\n",
            "  Using cached PyPika-0.48.9-py2.py3-none-any.whl\n",
            "Requirement already satisfied: tqdm>=4.65.0 in c:\\users\\nemat\\.conda\\envs\\markitdown\\lib\\site-packages (from chromadb) (4.67.1)\n",
            "Collecting overrides>=7.3.1 (from chromadb)\n",
            "  Using cached overrides-7.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting importlib-resources (from chromadb)\n",
            "  Downloading importlib_resources-6.5.2-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting grpcio>=1.58.0 (from chromadb)\n",
            "  Downloading grpcio-1.71.0-cp310-cp310-win_amd64.whl.metadata (4.0 kB)\n",
            "Collecting bcrypt>=4.0.1 (from chromadb)\n",
            "  Downloading bcrypt-4.3.0-cp39-abi3-win_amd64.whl.metadata (10 kB)\n",
            "Collecting typer>=0.9.0 (from chromadb)\n",
            "  Downloading typer-0.15.2-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting kubernetes>=28.1.0 (from chromadb)\n",
            "  Downloading kubernetes-32.0.1-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: tenacity>=8.2.3 in c:\\users\\nemat\\.conda\\envs\\markitdown\\lib\\site-packages (from chromadb) (9.0.0)\n",
            "Requirement already satisfied: PyYAML>=6.0.0 in c:\\users\\nemat\\.conda\\envs\\markitdown\\lib\\site-packages (from chromadb) (6.0.2)\n",
            "Collecting mmh3>=4.0.1 (from chromadb)\n",
            "  Downloading mmh3-5.1.0-cp310-cp310-win_amd64.whl.metadata (16 kB)\n",
            "Collecting orjson>=3.9.12 (from chromadb)\n",
            "  Downloading orjson-3.10.15-cp310-cp310-win_amd64.whl.metadata (42 kB)\n",
            "Requirement already satisfied: httpx>=0.27.0 in c:\\users\\nemat\\.conda\\envs\\markitdown\\lib\\site-packages (from chromadb) (0.28.1)\n",
            "Collecting rich>=10.11.0 (from chromadb)\n",
            "  Downloading rich-13.9.4-py3-none-any.whl.metadata (18 kB)\n",
            "Requirement already satisfied: packaging>=19.1 in c:\\users\\nemat\\.conda\\envs\\markitdown\\lib\\site-packages (from build>=1.0.3->chromadb) (24.2)\n",
            "Collecting pyproject_hooks (from build>=1.0.3->chromadb)\n",
            "  Using cached pyproject_hooks-1.2.0-py3-none-any.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: colorama in c:\\users\\nemat\\.conda\\envs\\markitdown\\lib\\site-packages (from build>=1.0.3->chromadb) (0.4.6)\n",
            "Collecting tomli>=1.1.0 (from build>=1.0.3->chromadb)\n",
            "  Downloading tomli-2.2.1-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting starlette<0.47.0,>=0.40.0 (from fastapi>=0.95.2->chromadb)\n",
            "  Downloading starlette-0.46.1-py3-none-any.whl.metadata (6.2 kB)\n",
            "Requirement already satisfied: anyio in c:\\users\\nemat\\.conda\\envs\\markitdown\\lib\\site-packages (from httpx>=0.27.0->chromadb) (4.7.0)\n",
            "Requirement already satisfied: certifi in c:\\users\\nemat\\.conda\\envs\\markitdown\\lib\\site-packages (from httpx>=0.27.0->chromadb) (2024.12.14)\n",
            "Requirement already satisfied: httpcore==1.* in c:\\users\\nemat\\.conda\\envs\\markitdown\\lib\\site-packages (from httpx>=0.27.0->chromadb) (1.0.7)\n",
            "Requirement already satisfied: idna in c:\\users\\nemat\\.conda\\envs\\markitdown\\lib\\site-packages (from httpx>=0.27.0->chromadb) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\nemat\\.conda\\envs\\markitdown\\lib\\site-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.14.0)\n",
            "Requirement already satisfied: six>=1.9.0 in c:\\users\\nemat\\.conda\\envs\\markitdown\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in c:\\users\\nemat\\.conda\\envs\\markitdown\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2.9.0.post0)\n",
            "Collecting google-auth>=1.0.1 (from kubernetes>=28.1.0->chromadb)\n",
            "  Downloading google_auth-2.38.0-py2.py3-none-any.whl.metadata (4.8 kB)\n",
            "Collecting websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 (from kubernetes>=28.1.0->chromadb)\n",
            "  Using cached websocket_client-1.8.0-py3-none-any.whl.metadata (8.0 kB)\n",
            "Requirement already satisfied: requests in c:\\users\\nemat\\.conda\\envs\\markitdown\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2.32.3)\n",
            "Collecting requests-oauthlib (from kubernetes>=28.1.0->chromadb)\n",
            "  Using cached requests_oauthlib-2.0.0-py2.py3-none-any.whl.metadata (11 kB)\n",
            "Collecting oauthlib>=3.2.2 (from kubernetes>=28.1.0->chromadb)\n",
            "  Using cached oauthlib-3.2.2-py3-none-any.whl.metadata (7.5 kB)\n",
            "Requirement already satisfied: urllib3>=1.24.2 in c:\\users\\nemat\\.conda\\envs\\markitdown\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2.3.0)\n",
            "Collecting durationpy>=0.7 (from kubernetes>=28.1.0->chromadb)\n",
            "  Using cached durationpy-0.9-py3-none-any.whl.metadata (338 bytes)\n",
            "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb)\n",
            "  Using cached coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Collecting flatbuffers (from onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading flatbuffers-25.2.10-py2.py3-none-any.whl.metadata (875 bytes)\n",
            "Requirement already satisfied: protobuf in c:\\users\\nemat\\.conda\\envs\\markitdown\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (6.30.1)\n",
            "Collecting sympy (from onnxruntime>=1.14.1->chromadb)\n",
            "  Using cached sympy-1.13.3-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting deprecated>=1.2.6 (from opentelemetry-api>=1.2.0->chromadb)\n",
            "  Downloading Deprecated-1.2.18-py2.py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting importlib-metadata<8.7.0,>=6.0 (from opentelemetry-api>=1.2.0->chromadb)\n",
            "  Downloading importlib_metadata-8.6.1-py3-none-any.whl.metadata (4.7 kB)\n",
            "Collecting googleapis-common-protos~=1.52 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
            "  Downloading googleapis_common_protos-1.69.2-py3-none-any.whl.metadata (9.3 kB)\n",
            "Collecting opentelemetry-exporter-otlp-proto-common==1.31.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_common-1.31.0-py3-none-any.whl.metadata (1.9 kB)\n",
            "Collecting opentelemetry-proto==1.31.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
            "  Downloading opentelemetry_proto-1.31.0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting protobuf (from onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading protobuf-5.29.3-cp310-abi3-win_amd64.whl.metadata (592 bytes)\n",
            "Collecting opentelemetry-instrumentation-asgi==0.52b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading opentelemetry_instrumentation_asgi-0.52b0-py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting opentelemetry-instrumentation==0.52b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading opentelemetry_instrumentation-0.52b0-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting opentelemetry-semantic-conventions==0.52b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading opentelemetry_semantic_conventions-0.52b0-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting opentelemetry-util-http==0.52b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading opentelemetry_util_http-0.52b0-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in c:\\users\\nemat\\.conda\\envs\\markitdown\\lib\\site-packages (from opentelemetry-instrumentation==0.52b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (1.17.2)\n",
            "Collecting asgiref~=3.0 (from opentelemetry-instrumentation-asgi==0.52b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Using cached asgiref-3.8.1-py3-none-any.whl.metadata (9.3 kB)\n",
            "Collecting monotonic>=1.5 (from posthog>=2.4.0->chromadb)\n",
            "  Using cached monotonic-1.6-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: backoff>=1.10.0 in c:\\users\\nemat\\.conda\\envs\\markitdown\\lib\\site-packages (from posthog>=2.4.0->chromadb) (2.2.1)\n",
            "Requirement already satisfied: distro>=1.5.0 in c:\\users\\nemat\\.conda\\envs\\markitdown\\lib\\site-packages (from posthog>=2.4.0->chromadb) (1.9.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\nemat\\.conda\\envs\\markitdown\\lib\\site-packages (from pydantic>=1.9->chromadb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in c:\\users\\nemat\\.conda\\envs\\markitdown\\lib\\site-packages (from pydantic>=1.9->chromadb) (2.27.2)\n",
            "Collecting markdown-it-py>=2.2.0 (from rich>=10.11.0->chromadb)\n",
            "  Using cached markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\nemat\\.conda\\envs\\markitdown\\lib\\site-packages (from rich>=10.11.0->chromadb) (2.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in c:\\users\\nemat\\.conda\\envs\\markitdown\\lib\\site-packages (from tokenizers>=0.13.2->chromadb) (0.29.3)\n",
            "Requirement already satisfied: click>=8.0.0 in c:\\users\\nemat\\.conda\\envs\\markitdown\\lib\\site-packages (from typer>=0.9.0->chromadb) (8.1.8)\n",
            "Collecting shellingham>=1.3.0 (from typer>=0.9.0->chromadb)\n",
            "  Using cached shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting httptools>=0.6.3 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading httptools-0.6.4-cp310-cp310-win_amd64.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: python-dotenv>=0.13 in c:\\users\\nemat\\.conda\\envs\\markitdown\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.1)\n",
            "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading watchfiles-1.0.4-cp310-cp310-win_amd64.whl.metadata (5.0 kB)\n",
            "Collecting websockets>=10.4 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading websockets-15.0.1-cp310-cp310-win_amd64.whl.metadata (7.0 kB)\n",
            "Collecting cachetools<6.0,>=2.0.0 (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb)\n",
            "  Downloading cachetools-5.5.2-py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting pyasn1-modules>=0.2.1 (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb)\n",
            "  Using cached pyasn1_modules-0.4.1-py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting rsa<5,>=3.1.4 (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb)\n",
            "  Using cached rsa-4.9-py3-none-any.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: filelock in c:\\users\\nemat\\.conda\\envs\\markitdown\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\nemat\\.conda\\envs\\markitdown\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2025.3.0)\n",
            "Collecting zipp>=3.20 (from importlib-metadata<8.7.0,>=6.0->opentelemetry-api>=1.2.0->chromadb)\n",
            "  Using cached zipp-3.21.0-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb)\n",
            "  Using cached mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\nemat\\.conda\\envs\\markitdown\\lib\\site-packages (from requests->kubernetes>=28.1.0->chromadb) (3.4.1)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\nemat\\.conda\\envs\\markitdown\\lib\\site-packages (from anyio->httpx>=0.27.0->chromadb) (1.2.2)\n",
            "Requirement already satisfied: sniffio>=1.1 in c:\\users\\nemat\\.conda\\envs\\markitdown\\lib\\site-packages (from anyio->httpx>=0.27.0->chromadb) (1.3.1)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb)\n",
            "  Using cached humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Collecting mpmath<1.4,>=1.1.0 (from sympy->onnxruntime>=1.14.1->chromadb)\n",
            "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
            "Collecting pyreadline3 (from humanfriendly>=9.1->coloredlogs->onnxruntime>=1.14.1->chromadb)\n",
            "  Using cached pyreadline3-3.5.4-py3-none-any.whl.metadata (4.7 kB)\n",
            "Collecting pyasn1<0.7.0,>=0.4.6 (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb)\n",
            "  Using cached pyasn1-0.6.1-py3-none-any.whl.metadata (8.4 kB)\n",
            "Downloading chromadb-0.6.3-py3-none-any.whl (611 kB)\n",
            "   ---------------------------------------- 0.0/611.1 kB ? eta -:--:--\n",
            "   ---------------------------------------- 611.1/611.1 kB 7.6 MB/s eta 0:00:00\n",
            "Using cached chroma_hnswlib-0.7.6-cp310-cp310-win_amd64.whl (150 kB)\n",
            "Downloading bcrypt-4.3.0-cp39-abi3-win_amd64.whl (152 kB)\n",
            "Downloading build-1.2.2.post1-py3-none-any.whl (22 kB)\n",
            "Downloading fastapi-0.115.11-py3-none-any.whl (94 kB)\n",
            "Downloading grpcio-1.71.0-cp310-cp310-win_amd64.whl (4.3 MB)\n",
            "   ---------------------------------------- 0.0/4.3 MB ? eta -:--:--\n",
            "   ---------------------------------------  4.2/4.3 MB 27.9 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 4.3/4.3 MB 18.3 MB/s eta 0:00:00\n",
            "Downloading kubernetes-32.0.1-py2.py3-none-any.whl (2.0 MB)\n",
            "   ---------------------------------------- 0.0/2.0 MB ? eta -:--:--\n",
            "   ---------------------------------------- 2.0/2.0 MB 18.4 MB/s eta 0:00:00\n",
            "Downloading mmh3-5.1.0-cp310-cp310-win_amd64.whl (41 kB)\n",
            "Downloading onnxruntime-1.21.0-cp310-cp310-win_amd64.whl (11.8 MB)\n",
            "   ---------------------------------------- 0.0/11.8 MB ? eta -:--:--\n",
            "   ------------------------------------- -- 11.0/11.8 MB 52.9 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 11.8/11.8 MB 29.4 MB/s eta 0:00:00\n",
            "Downloading opentelemetry_api-1.31.0-py3-none-any.whl (65 kB)\n",
            "Downloading opentelemetry_exporter_otlp_proto_grpc-1.31.0-py3-none-any.whl (18 kB)\n",
            "Downloading opentelemetry_exporter_otlp_proto_common-1.31.0-py3-none-any.whl (18 kB)\n",
            "Downloading opentelemetry_proto-1.31.0-py3-none-any.whl (55 kB)\n",
            "Downloading opentelemetry_instrumentation_fastapi-0.52b0-py3-none-any.whl (12 kB)\n",
            "Downloading opentelemetry_instrumentation-0.52b0-py3-none-any.whl (31 kB)\n",
            "Downloading opentelemetry_instrumentation_asgi-0.52b0-py3-none-any.whl (16 kB)\n",
            "Downloading opentelemetry_semantic_conventions-0.52b0-py3-none-any.whl (183 kB)\n",
            "Downloading opentelemetry_util_http-0.52b0-py3-none-any.whl (7.3 kB)\n",
            "Downloading opentelemetry_sdk-1.31.0-py3-none-any.whl (118 kB)\n",
            "Downloading orjson-3.10.15-cp310-cp310-win_amd64.whl (133 kB)\n",
            "Using cached overrides-7.7.0-py3-none-any.whl (17 kB)\n",
            "Downloading posthog-3.21.0-py2.py3-none-any.whl (79 kB)\n",
            "Downloading rich-13.9.4-py3-none-any.whl (242 kB)\n",
            "Downloading typer-0.15.2-py3-none-any.whl (45 kB)\n",
            "Downloading uvicorn-0.34.0-py3-none-any.whl (62 kB)\n",
            "Downloading importlib_resources-6.5.2-py3-none-any.whl (37 kB)\n",
            "Downloading Deprecated-1.2.18-py2.py3-none-any.whl (10.0 kB)\n",
            "Using cached durationpy-0.9-py3-none-any.whl (3.5 kB)\n",
            "Downloading google_auth-2.38.0-py2.py3-none-any.whl (210 kB)\n",
            "Downloading googleapis_common_protos-1.69.2-py3-none-any.whl (293 kB)\n",
            "Downloading httptools-0.6.4-cp310-cp310-win_amd64.whl (88 kB)\n",
            "Downloading importlib_metadata-8.6.1-py3-none-any.whl (26 kB)\n",
            "Using cached markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
            "Using cached monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
            "Using cached oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
            "Downloading protobuf-5.29.3-cp310-abi3-win_amd64.whl (434 kB)\n",
            "Using cached shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
            "Downloading starlette-0.46.1-py3-none-any.whl (71 kB)\n",
            "Downloading tomli-2.2.1-py3-none-any.whl (14 kB)\n",
            "Downloading watchfiles-1.0.4-cp310-cp310-win_amd64.whl (284 kB)\n",
            "Using cached websocket_client-1.8.0-py3-none-any.whl (58 kB)\n",
            "Downloading websockets-15.0.1-cp310-cp310-win_amd64.whl (176 kB)\n",
            "Using cached coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "Downloading flatbuffers-25.2.10-py2.py3-none-any.whl (30 kB)\n",
            "Using cached pyproject_hooks-1.2.0-py3-none-any.whl (10 kB)\n",
            "Using cached requests_oauthlib-2.0.0-py2.py3-none-any.whl (24 kB)\n",
            "Using cached sympy-1.13.3-py3-none-any.whl (6.2 MB)\n",
            "Using cached asgiref-3.8.1-py3-none-any.whl (23 kB)\n",
            "Downloading cachetools-5.5.2-py3-none-any.whl (10 kB)\n",
            "Using cached humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
            "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
            "Using cached pyasn1_modules-0.4.1-py3-none-any.whl (181 kB)\n",
            "Using cached rsa-4.9-py3-none-any.whl (34 kB)\n",
            "Using cached zipp-3.21.0-py3-none-any.whl (9.6 kB)\n",
            "Using cached pyasn1-0.6.1-py3-none-any.whl (83 kB)\n",
            "Using cached pyreadline3-3.5.4-py3-none-any.whl (83 kB)\n",
            "Installing collected packages: pypika, mpmath, monotonic, flatbuffers, durationpy, zipp, websockets, websocket-client, tomli, sympy, shellingham, pyreadline3, pyproject_hooks, pyasn1, protobuf, overrides, orjson, opentelemetry-util-http, oauthlib, mmh3, mdurl, importlib-resources, httptools, grpcio, deprecated, chroma-hnswlib, cachetools, bcrypt, asgiref, watchfiles, uvicorn, starlette, rsa, requests-oauthlib, pyasn1-modules, posthog, opentelemetry-proto, markdown-it-py, importlib-metadata, humanfriendly, googleapis-common-protos, build, rich, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, google-auth, fastapi, coloredlogs, typer, opentelemetry-semantic-conventions, onnxruntime, kubernetes, opentelemetry-sdk, opentelemetry-instrumentation, opentelemetry-instrumentation-asgi, opentelemetry-exporter-otlp-proto-grpc, opentelemetry-instrumentation-fastapi, chromadb\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 6.30.1\n",
            "    Uninstalling protobuf-6.30.1:\n",
            "      Successfully uninstalled protobuf-6.30.1\n",
            "Successfully installed asgiref-3.8.1 bcrypt-4.3.0 build-1.2.2.post1 cachetools-5.5.2 chroma-hnswlib-0.7.6 chromadb-0.6.3 coloredlogs-15.0.1 deprecated-1.2.18 durationpy-0.9 fastapi-0.115.11 flatbuffers-25.2.10 google-auth-2.38.0 googleapis-common-protos-1.69.2 grpcio-1.71.0 httptools-0.6.4 humanfriendly-10.0 importlib-metadata-8.6.1 importlib-resources-6.5.2 kubernetes-32.0.1 markdown-it-py-3.0.0 mdurl-0.1.2 mmh3-5.1.0 monotonic-1.6 mpmath-1.3.0 oauthlib-3.2.2 onnxruntime-1.21.0 opentelemetry-api-1.31.0 opentelemetry-exporter-otlp-proto-common-1.31.0 opentelemetry-exporter-otlp-proto-grpc-1.31.0 opentelemetry-instrumentation-0.52b0 opentelemetry-instrumentation-asgi-0.52b0 opentelemetry-instrumentation-fastapi-0.52b0 opentelemetry-proto-1.31.0 opentelemetry-sdk-1.31.0 opentelemetry-semantic-conventions-0.52b0 opentelemetry-util-http-0.52b0 orjson-3.10.15 overrides-7.7.0 posthog-3.21.0 protobuf-5.29.3 pyasn1-0.6.1 pyasn1-modules-0.4.1 pypika-0.48.9 pyproject_hooks-1.2.0 pyreadline3-3.5.4 requests-oauthlib-2.0.0 rich-13.9.4 rsa-4.9 shellingham-1.5.4 starlette-0.46.1 sympy-1.13.3 tomli-2.2.1 typer-0.15.2 uvicorn-0.34.0 watchfiles-1.0.4 websocket-client-1.8.0 websockets-15.0.1 zipp-3.21.0\n",
            "Collecting semantic_text_splitter\n",
            "  Downloading semantic_text_splitter-0.24.1-cp39-abi3-win_amd64.whl.metadata (7.9 kB)\n",
            "Downloading semantic_text_splitter-0.24.1-cp39-abi3-win_amd64.whl (7.8 MB)\n",
            "   ---------------------------------------- 0.0/7.8 MB ? eta -:--:--\n",
            "   --------------------------------- ------ 6.6/7.8 MB 36.6 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 7.8/7.8 MB 25.4 MB/s eta 0:00:00\n",
            "Installing collected packages: semantic_text_splitter\n",
            "Successfully installed semantic_text_splitter-0.24.1\n"
          ]
        }
      ],
      "source": [
        "!pip install indoxArcg\n",
        "!pip install transformers\n",
        "!pip install torch\n",
        "!pip install openai\n",
        "!pip install chromadb\n",
        "!pip install semantic_text_splitter"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ad09035513fec084",
      "metadata": {
        "id": "ad09035513fec084"
      },
      "source": [
        "## Setting Up the Python Environment\n",
        "\n",
        "If you are running this project in your local IDE, please create a Python environment to ensure all dependencies are correctly managed. You can follow the steps below to set up a virtual environment named `indoxArcg`:\n",
        "\n",
        "### Windows\n",
        "\n",
        "1. **Create the virtual environment:**\n",
        "```bash\n",
        "python -m venv indoxArcg\n",
        "```\n",
        "2. **Activate the virtual environment:**\n",
        "```bash\n",
        "indoxArcg\\Scripts\\activate\n",
        "```\n",
        "\n",
        "### macOS/Linux\n",
        "\n",
        "1. **Create the virtual environment:**\n",
        "   ```bash\n",
        "   python3 -m venv indoxArcg\n",
        "```\n",
        "\n",
        "2. **Activate the virtual environment:**\n",
        "    ```bash\n",
        "   source indoxArcg/bin/activate\n",
        "```\n",
        "### Install Dependencies\n",
        "\n",
        "Once the virtual environment is activated, install the required dependencies by running:\n",
        "\n",
        "```bash\n",
        "pip install -r requirements.txt\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "ec319043",
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "load_dotenv()\n",
        "\n",
        "\n",
        "OPENAI_API_KEY=os.getenv(\"OPENAI_API_KEY\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ac995737f9b2fe6e",
      "metadata": {
        "id": "ac995737f9b2fe6e"
      },
      "source": [
        "## Initial Setup\n",
        "\n",
        "The following imports are essential for setting up the Indox application. These imports include the main Indox retrieval augmentation module, question-answering models, embeddings, and data loader splitter."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "759db8f502cbd91f",
      "metadata": {
        "id": "759db8f502cbd91f"
      },
      "source": [
        "### Generating response using OpenAI's language models\n",
        "OpenAIQA class is used to handle question-answering task using OpenAI's language models. This instance creates OpenAiEmbedding class to specifying embedding model. Here ChromaVectorStore handles the storage and retrieval of vector embeddings by specifying a collection name and sets up a vector store where text embeddings can be stored and queried."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ceee362a",
      "metadata": {},
      "source": [
        "if you have an issue like ModuleNotFoundError: No module named 'torch', you can install torch by running the following command:\n",
        "```bash\n",
        "pip install torch\n",
        "```\n",
        "\n",
        "if you have an issue like ModuleNotFoundError: No module named 'transformers', you can install transformers by running the following command:\n",
        "```bash\n",
        "pip install transformers\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "y0ZTICPr71Nl",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 826
        },
        "id": "y0ZTICPr71Nl",
        "outputId": "b9d598a1-aca4-4370-e325-9ae955d120a7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: numpy in c:\\users\\nemat\\.conda\\envs\\markitdown\\lib\\site-packages (2.2.4)\n",
            "Requirement already satisfied: transformers in c:\\users\\nemat\\.conda\\envs\\markitdown\\lib\\site-packages (4.49.0)\n",
            "Collecting torch\n",
            "  Downloading torch-2.6.0-cp310-cp310-win_amd64.whl.metadata (28 kB)\n",
            "Requirement already satisfied: filelock in c:\\users\\nemat\\.conda\\envs\\markitdown\\lib\\site-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in c:\\users\\nemat\\.conda\\envs\\markitdown\\lib\\site-packages (from transformers) (0.29.3)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\nemat\\.conda\\envs\\markitdown\\lib\\site-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\nemat\\.conda\\envs\\markitdown\\lib\\site-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\nemat\\.conda\\envs\\markitdown\\lib\\site-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in c:\\users\\nemat\\.conda\\envs\\markitdown\\lib\\site-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\nemat\\.conda\\envs\\markitdown\\lib\\site-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\nemat\\.conda\\envs\\markitdown\\lib\\site-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in c:\\users\\nemat\\.conda\\envs\\markitdown\\lib\\site-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\nemat\\.conda\\envs\\markitdown\\lib\\site-packages (from torch) (4.12.2)\n",
            "Collecting networkx (from torch)\n",
            "  Downloading networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting jinja2 (from torch)\n",
            "  Downloading jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: fsspec in c:\\users\\nemat\\.conda\\envs\\markitdown\\lib\\site-packages (from torch) (2025.3.0)\n",
            "Collecting sympy==1.13.1 (from torch)\n",
            "  Using cached sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\nemat\\.conda\\envs\\markitdown\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: colorama in c:\\users\\nemat\\.conda\\envs\\markitdown\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
            "Collecting MarkupSafe>=2.0 (from jinja2->torch)\n",
            "  Downloading MarkupSafe-3.0.2-cp310-cp310-win_amd64.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\nemat\\.conda\\envs\\markitdown\\lib\\site-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\nemat\\.conda\\envs\\markitdown\\lib\\site-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\nemat\\.conda\\envs\\markitdown\\lib\\site-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\nemat\\.conda\\envs\\markitdown\\lib\\site-packages (from requests->transformers) (2024.12.14)\n",
            "Downloading torch-2.6.0-cp310-cp310-win_amd64.whl (204.2 MB)\n",
            "   ---------------------------------------- 0.0/204.2 MB ? eta -:--:--\n",
            "   - -------------------------------------- 8.4/204.2 MB 47.2 MB/s eta 0:00:05\n",
            "   --- ------------------------------------ 18.4/204.2 MB 46.4 MB/s eta 0:00:05\n",
            "   ----- ---------------------------------- 28.6/204.2 MB 46.5 MB/s eta 0:00:04\n",
            "   ------- -------------------------------- 40.1/204.2 MB 48.1 MB/s eta 0:00:04\n",
            "   --------- ------------------------------ 50.3/204.2 MB 48.6 MB/s eta 0:00:04\n",
            "   ----------- ---------------------------- 58.7/204.2 MB 46.8 MB/s eta 0:00:04\n",
            "   ------------- -------------------------- 68.4/204.2 MB 46.4 MB/s eta 0:00:03\n",
            "   --------------- ------------------------ 77.3/204.2 MB 46.1 MB/s eta 0:00:03\n",
            "   ----------------- ---------------------- 87.3/204.2 MB 46.0 MB/s eta 0:00:03\n",
            "   ------------------- -------------------- 97.8/204.2 MB 46.2 MB/s eta 0:00:03\n",
            "   -------------------- ------------------ 107.2/204.2 MB 45.9 MB/s eta 0:00:03\n",
            "   ---------------------- ---------------- 117.2/204.2 MB 45.9 MB/s eta 0:00:02\n",
            "   ------------------------ -------------- 126.9/204.2 MB 46.3 MB/s eta 0:00:02\n",
            "   -------------------------- ------------ 136.3/204.2 MB 46.1 MB/s eta 0:00:02\n",
            "   --------------------------- ----------- 146.3/204.2 MB 46.0 MB/s eta 0:00:02\n",
            "   ----------------------------- --------- 155.7/204.2 MB 46.1 MB/s eta 0:00:02\n",
            "   ------------------------------- ------- 167.0/204.2 MB 46.4 MB/s eta 0:00:01\n",
            "   --------------------------------- ----- 177.7/204.2 MB 46.7 MB/s eta 0:00:01\n",
            "   ----------------------------------- --- 186.9/204.2 MB 46.5 MB/s eta 0:00:01\n",
            "   ------------------------------------ -- 192.4/204.2 MB 45.4 MB/s eta 0:00:01\n",
            "   --------------------------------------  199.2/204.2 MB 44.8 MB/s eta 0:00:01\n",
            "   --------------------------------------  203.9/204.2 MB 44.3 MB/s eta 0:00:01\n",
            "   --------------------------------------  203.9/204.2 MB 44.3 MB/s eta 0:00:01\n",
            "   --------------------------------------  203.9/204.2 MB 44.3 MB/s eta 0:00:01\n",
            "   --------------------------------------  203.9/204.2 MB 44.3 MB/s eta 0:00:01\n",
            "   --------------------------------------  203.9/204.2 MB 44.3 MB/s eta 0:00:01\n",
            "   --------------------------------------  203.9/204.2 MB 44.3 MB/s eta 0:00:01\n",
            "   --------------------------------------  203.9/204.2 MB 44.3 MB/s eta 0:00:01\n",
            "   --------------------------------------  203.9/204.2 MB 44.3 MB/s eta 0:00:01\n",
            "   --------------------------------------  203.9/204.2 MB 44.3 MB/s eta 0:00:01\n",
            "   --------------------------------------  203.9/204.2 MB 44.3 MB/s eta 0:00:01\n",
            "   --------------------------------------  203.9/204.2 MB 44.3 MB/s eta 0:00:01\n",
            "   --------------------------------------  203.9/204.2 MB 44.3 MB/s eta 0:00:01\n",
            "   --------------------------------------- 204.2/204.2 MB 28.6 MB/s eta 0:00:00\n",
            "Using cached sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
            "Downloading jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
            "Downloading networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
            "   ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
            "   ---------------------------------------- 1.7/1.7 MB 18.7 MB/s eta 0:00:00\n",
            "Downloading MarkupSafe-3.0.2-cp310-cp310-win_amd64.whl (15 kB)\n",
            "Installing collected packages: sympy, networkx, MarkupSafe, jinja2, torch\n",
            "  Attempting uninstall: sympy\n",
            "    Found existing installation: sympy 1.13.3\n",
            "    Uninstalling sympy-1.13.3:\n",
            "      Successfully uninstalled sympy-1.13.3\n",
            "Successfully installed MarkupSafe-3.0.2 jinja2-3.1.6 networkx-3.4.2 sympy-1.13.1 torch-2.6.0\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade numpy transformers torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "PGVE2Vht7o5F",
      "metadata": {
        "id": "PGVE2Vht7o5F"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\nemat\\.conda\\envs\\MarkitDown\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m: \u001b[1mInitializing OpenAi with model: gpt-4o-mini\u001b[0m\n",
            "\u001b[32mINFO\u001b[0m: \u001b[1mOpenAi initialized successfully\u001b[0m\n",
            "\u001b[32mINFO\u001b[0m: \u001b[1mInitialized OpenAiEmbedding with model: text-embedding-3-small\u001b[0m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-03-19 02:32:56,621 - chromadb.telemetry.product.posthog - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.\n"
          ]
        }
      ],
      "source": [
        "# Initialize OpenAI language model and embedding model with API key\n",
        "# Set up Chroma vector store for storing and retrieving embeddings\n",
        "from indoxArcg.embeddings import OpenAiEmbedding\n",
        "from indoxArcg.llms import OpenAi # if you have an issue, please run \"!pip install --upgrade numpy transformers\"\n",
        "\n",
        "openai_qa = OpenAi(api_key=OPENAI_API_KEY, model=\"gpt-4o-mini\")\n",
        "embed_openai = OpenAiEmbedding(api_key=OPENAI_API_KEY, model=\"text-embedding-3-small\")\n",
        "\n",
        "from indoxArcg.vector_stores import Chroma\n",
        "db = Chroma(collection_name=\"sample\", embedding_function=embed_openai)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1e3408e8f8a8ad17",
      "metadata": {
        "id": "1e3408e8f8a8ad17"
      },
      "source": [
        "### load and preprocess data\n",
        "This part of code demonstrates how to load and preprocess text data from a file, split it into chunks, and store these chunks in the vector store that was set up previously."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "e765b79a32060e9e",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-08-17T11:00:23.407526Z",
          "start_time": "2024-08-17T11:00:23.224598Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e765b79a32060e9e",
        "outputId": "bb198e42-ab60-4291-b2b1-92cae2e62f38"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The wife of a rich man fell sick, and as she felt that her end\n",
            "was drawing near, she called her only daughter to her bedside and\n",
            "said, dear child, be good and pious, and then the\n",
            "good God will always protect you, and I will look down on you\n",
            "from heaven and be near you.  Thereupon she closed her eyes and\n",
            "departed.  Every day the maiden went out to her mother's grave,\n",
            "and wept, and she remained pious and good.  When winter came\n",
            "the snow spread a white sheet over the grave, and by the time the\n",
            "spring sun had drawn it off again, the man had taken another wife.\n",
            "The woman had brought with her into the house two daughters,\n",
            "who were beautiful and fair of face, but vile and black of heart.\n",
            "Now began a bad time for the poor step-child.  Is the stupid goose\n",
            "to sit in the parlor with us, they said.  He who wants to eat bread\n",
            "must earn it.  Out with the kitchen-wench.  They took her pretty\n",
            "clothes away from her, put an old grey bedgown on her, and gave\n",
            "her wooden shoes.  Just look at the proud princess, how decked\n",
            "out she is, they cried, and laughed, and led her into the kitchen.\n",
            "There she had to do hard work from morning till night, get up\n",
            "before daybreak, carry water, light fires, cook and wash.  Besides\n",
            "this, the sisters did her every imaginable injury - they mocked her\n",
            "and emptied her peas and lentils into the ashes, so that she was\n",
            "forced to sit and pick them out again.  In the evening when she had\n",
            "worked till she was weary she had no bed to go to, but had to sleep\n",
            "by the hearth in the cinders.  And as on that account she always\n",
            "looked dusty and dirty, they called her cinderella.\n",
            "It happened that the father was once going to the fair, and he\n",
            "asked his two step-daughters what he should bring back for them.\n",
            "Beautiful dresses, said one, pearls and jewels, said the second.\n",
            "And you, cinderella, said he, what will you have.  Father\n",
            "break off for me the first branch which knocks against your hat on\n",
            "your way home.  So he bought beautiful dresses, pearls and jewels\n",
            "for his two step-daughters, and on his way home, as he was riding\n",
            "through a green thicket, a hazel twig brushed against him and\n",
            "knocked off his hat.  Then he broke off the branch and took it with\n",
            "him.  When he reached home he gave his step-daughters the things\n",
            "which they had wished for, and to cinderella he gave the branch\n",
            "from the hazel-bush.  Cinderella thanked him, went to her mother's\n",
            "grave and planted the branch on it, and wept so much that the tears\n",
            "fell down on it and watered it.  And it grew and became a handsome\n",
            "tree. Thrice a day cinderella went and sat beneath it, and wept and\n",
            "prayed, and a little white bird always came on the tree, and if\n",
            "cinderella expressed a wish, the bird threw down to her what she\n",
            "had wished for.\n",
            "It happened, however, that the king gave orders for a festival\n",
            "which was to last three days, and to which all the beautiful young\n",
            "girls in the country were invited, in order that his son might choose\n",
            "himself a bride.  When the two step-sisters heard that they too were\n",
            "to appear among the number, they were delighted, called cinderella\n",
            "and said, comb our hair for us, brush our shoes and fasten our\n",
            "buckles, for we are going to the wedding at the king's palace.\n",
            "Cinderella obeyed, but wept, because she too would have liked to\n",
            "go with them to the dance, and begged her step-mother to allow\n",
            "her to do so.  You go, cinderella, said she, covered in dust and\n",
            "dirt as you are, and would go to the festival.  You have no clothes\n",
            "and shoes, and yet would dance.  As, however, cinderella went on\n",
            "asking, the step-mother said at last, I have emptied a dish of\n",
            "lentils into the ashes for you, if you have picked them out again in\n",
            "two hours, you shall go with us.  The maiden went through the\n",
            "back-door into the garden, and called, you tame pigeons, you\n",
            "turtle-doves, and all you birds beneath the sky, come and help me\n",
            "to pick\n",
            "     the good into the pot,\n",
            "     the bad into the crop.\n",
            "Then two white pigeons came in by the kitchen window, and\n",
            "afterwards the turtle-doves, and at last all the birds beneath the\n",
            "sky, came whirring and crowding in, and alighted amongst the ashes.\n",
            "And the pigeons nodded with their heads and began pick, pick,\n",
            "pick, pick, and the rest began also pick, pick, pick, pick, and\n",
            "gathered all the good grains into the dish.  Hardly had one hour\n",
            "passed before they had finished, and all flew out again.  Then the\n",
            "girl took the dish to her step-mother, and was glad, and believed\n",
            "that now she would be allowed to go with them to the festival.\n",
            "But the step-mother said, no, cinderella, you have no clothes and\n",
            "you can not dance.  You would only be laughed at.  And as\n",
            "cinderella wept at this, the step-mother said, if you can pick two\n",
            "dishes of lentils out of the ashes for me in one hour, you shall go\n",
            "with us.  And she thought to herself, that she most certainly\n",
            "cannot do again.  When the step-mother had emptied the two\n",
            "dishes of lentils amongst the ashes, the maiden went through the\n",
            "back-door into the garden and cried, you tame pigeons, you\n",
            "turtle-doves, and all you birds beneath the sky, come and help me\n",
            "to pick\n",
            "     the good into the pot,\n",
            "     the bad into the crop.\n",
            "Then two white pigeons came in by the kitchen-window, and\n",
            "afterwards the turtle-doves, and at length all the birds beneath the\n",
            "sky, came whirring and crowding in, and alighted amongst the\n",
            "ashes.  And the doves nodded with their heads and began pick,\n",
            "pick, pick, pick, and the others began also pick, pick, pick, pick,\n",
            "and gathered all the good seeds into the dishes, and before half an\n",
            "hour was over they had already finished, and all flew out again.\n",
            "Then the maiden was delighted, and believed that she might now go\n",
            "with them to the wedding.  But the step-mother said, all this will\n",
            "not help.  You cannot go with us, for you have no clothes and can\n",
            "not dance.  We should be ashamed of you.  On this she turned her\n",
            "back on cinderella, and hurried away with her two proud daughters.\n",
            "As no one was now at home, cinderella went to her mother's\n",
            "grave beneath the hazel-tree, and cried -\n",
            "     shiver and quiver, little tree,\n",
            "     silver and gold throw down over me.\n",
            "Then the bird threw a gold and silver dress down to her, and\n",
            "slippers embroidered with silk and silver.  She put on the dress\n",
            "with all speed, and went to the wedding.  Her step-sisters and the\n",
            "step-mother however did not know her, and thought she must be a\n",
            "foreign princess, for she looked so beautiful in the golden dress.\n",
            "They never once thought of cinderella, and believed that she was\n",
            "sitting at home in the dirt, picking lentils out of the ashes.  The\n",
            "prince approached her, took her by the hand and danced with her.\n",
            "He would dance with no other maiden, and never let loose of her\n",
            "hand, and if any one else came to invite her, he said, this is my\n",
            "partner.\n",
            "She danced till it was evening, and then she wanted to go home.\n",
            "But the king's son said, I will go with you and bear you company,\n",
            "for he wished to see to whom the beautiful maiden belonged.\n",
            "She escaped from him, however, and sprang into the\n",
            "pigeon-house.  The king's son waited until her father came, and\n",
            "then he told him that the unknown maiden had leapt into the\n",
            "pigeon-house.  The old man thought, can it be cinderella.  And\n",
            "they had to bring him an axe and a pickaxe that he might hew\n",
            "the pigeon-house to pieces, but no one was inside it.  And when they\n",
            "got home cinderella lay in her dirty clothes among the ashes, and\n",
            "a dim little oil-lamp was burning on the mantle-piece, for\n",
            "cinderella had jumped quickly down from the back of the pigeon-house\n",
            "and had run to the little hazel-tree, and there she had taken off\n",
            "her beautiful clothes and laid them on the grave, and the bird had\n",
            "taken them away again, and then she had seated herself in the\n",
            "kitchen amongst the ashes in her grey gown.\n",
            "Next day when the festival began afresh, and her parents and\n",
            "the step-sisters had gone once more, cinderella went to the\n",
            "hazel-tree and said -\n",
            "     shiver and quiver, my little tree,\n",
            "     silver and gold throw down over me.\n",
            "Then the bird threw down a much more beautiful dress than on\n",
            "the preceding day. And when cinderella appeared at the wedding\n",
            "in this dress, every one was astonished at her beauty.  The king's\n",
            "son had waited until she came, and instantly took her by the hand\n",
            "and danced with no one but her.  When others came and invited\n",
            "her, he said, this is my partner.  When evening came she wished\n",
            "to leave, and the king's son followed her and wanted to see into\n",
            "which house she went.  But she sprang away from him, and into\n",
            "the garden behind the house.  Therein stood a beautiful tall tree on\n",
            "which hung the most magnificent pears.  She clambered so nimbly\n",
            "between the branches like a squirrel that the king's son did not\n",
            "know where she was gone.  He waited until her father came, and\n",
            "said to him, the unknown maiden has escaped from me, and I\n",
            "believe she has climbed up the pear-tree.  The father thought,\n",
            "can it be cinderella.  And had an axe brought and cut the\n",
            "tree down, but no one was on it.  And when they got into the\n",
            "kitchen, cinderella lay there among the ashes, as usual, for she\n",
            "had jumped down on the other side of the tree, had taken the\n",
            "beautiful dress to the bird on the little hazel-tree, and put on her\n",
            "grey gown.\n",
            "On the third day, when the parents and sisters had gone away,\n",
            "cinderella went once more to her mother's grave and said to the\n",
            "little tree -\n",
            "     shiver and quiver, my little tree,\n",
            "     silver and gold throw down over me.\n",
            "And now the bird threw down to her a dress which was more\n",
            "splendid and magnificent than any she had yet had, and the\n",
            "slippers were golden.  And when she went to the festival in the\n",
            "dress, no one knew how to speak for astonishment.  The king's son\n",
            "danced with her only, and if any one invited her to dance, he said\n",
            "this is my partner.\n",
            "When evening came, cinderella wished to leave, and the king's\n",
            "son was anxious to go with her, but she escaped from him so quickly\n",
            "that he could not follow her.  The king's son, however, had\n",
            "employed a ruse, and had caused the whole staircase to be smeared\n",
            "with pitch, and there, when she ran down, had the maiden's left\n",
            "slipper remained stuck.  The king's son picked it up, and it was\n",
            "small and dainty, and all golden.  Next morning, he went with it to\n",
            "the father, and said to him, no one shall be my wife but she whose\n",
            "foot this golden slipper fits.  Then were the two sisters glad,\n",
            "for they had pretty feet.  The eldest went with the shoe into her\n",
            "room and wanted to try it on, and her mother stood by.  But she\n",
            "could not get her big toe into it, and the shoe was too small for\n",
            "her.  Then her mother gave her a knife and said, cut the toe off,\n",
            "when you are queen you will have no more need to go on foot.  The\n",
            "maiden cut the toe off, forced the foot into the shoe, swallowed\n",
            "the pain, and went out to the king's son.  Then he took her on his\n",
            "his horse as his bride and rode away with her.  They were\n",
            "obliged, however, to pass the grave, and there, on the hazel-tree,\n",
            "sat the two pigeons and cried -\n",
            "     turn and peep, turn and peep,\n",
            "     there's blood within the shoe,\n",
            "     the shoe it is too small for her,\n",
            "     the true bride waits for you.\n",
            "Then he looked at her foot and saw how the blood was trickling\n",
            "from it.  He turned his horse round and took the false bride\n",
            "home again, and said she was not the true one, and that the\n",
            "other sister was to put the shoe on.  Then this one went into her\n",
            "chamber and got her toes safely into the shoe, but her heel was\n",
            "too large.  So her mother gave her a knife and said,  cut a bit\n",
            "off your heel, when you are queen you will have no more need\n",
            "to go on foot.  The maiden cut a bit off her heel, forced\n",
            "her foot into the shoe, swallowed the pain, and went out to the\n",
            "king's son.  He took her on his horse as his bride, and rode away\n",
            "with her, but when they passed by the hazel-tree, the two pigeons\n",
            "sat on it and cried -\n",
            "     turn and peep, turn and peep,\n",
            "     there's blood within the shoe,\n",
            "     the shoe it is too small for her,\n",
            "     the true bride waits for you.\n",
            "He looked down at her foot and saw how the blood was running\n",
            "out of her shoe, and how it had stained her white stocking quite\n",
            "red.  Then he turned his horse and took the false bride home\n",
            "again.  This also is not the right one, said he, have you no\n",
            "other daughter.  No, said the man, there is still a little\n",
            "stunted kitchen-wench which my late wife left behind her, but\n",
            "she cannot possibly be the bride.  The king's son said he was\n",
            "to send her up to him, but the mother answered, oh, no, she is\n",
            "much too dirty, she cannot show herself.  But he absolutely\n",
            "insisted on it, and cinderella had to be called.  She first\n",
            "washed her hands and face clean, and then went and bowed down\n",
            "before the king's son, who gave her the golden shoe.  Then she\n",
            "seated herself on a stool, drew her foot out of the heavy\n",
            "wooden shoe, and put it into the slipper, which fitted like a\n",
            "glove.  And when she rose up and the king's son looked at her\n",
            "face he recognized the beautiful maiden who had danced with\n",
            "him and cried, that is the true bride.  The step-mother and\n",
            "the two sisters were horrified and became pale with rage, he,\n",
            "however, took cinderella on his horse and rode away with her.  As\n",
            "they passed by the hazel-tree, the two white doves cried -\n",
            "     turn and peep, turn and peep,\n",
            "     no blood is in the shoe,\n",
            "     the shoe is not too small for her,\n",
            "     the true bride rides with you,\n",
            "and when they had cried that, the two came flying down and\n",
            "placed themselves on cinderella's shoulders, one on the right,\n",
            "the other on the left, and remained sitting there.\n",
            "When the wedding with the king's son was to be celebrated, the\n",
            "two false sisters came and wanted to get into favor with\n",
            "cinderella and share her good fortune.  When the betrothed\n",
            "couple went to church, the elder was at the right side and the\n",
            "younger at the left, and the pigeons pecked out one eye from\n",
            "each of them.  Afterwards as they came back the elder was at\n",
            "the left, and the younger at the right, and then the pigeons\n",
            "pecked out the other eye from each.  And thus, for their\n",
            "wickedness and falsehood, they were punished with blindness\n",
            "all their days.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "'wget' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n"
          ]
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/osllmai/inDox/doc-v3/cookbook/indoxArcg/sample.txt\n",
        "\n",
        "# Check if the file is downloaded and display its content\n",
        "with open('sample.txt', 'r') as file:\n",
        "    content = file.read()\n",
        "    print(content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "1d8e56a9f88e03cf",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-09-01T08:47:15.288065Z",
          "start_time": "2024-09-01T08:47:15.283027Z"
        },
        "id": "1d8e56a9f88e03cf"
      },
      "outputs": [],
      "source": [
        "file_path = \"sample.txt\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "827c44ce67f972c7",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-09-01T08:48:25.155040Z",
          "start_time": "2024-09-01T08:48:25.146412Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "827c44ce67f972c7",
        "outputId": "dac6a1df-06b9-445c-9af0-0f74789b356f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'The wife of a rich man fell sick, and as she felt that her end\\nwas drawing near, she called her only'"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from indoxArcg.data_loaders import Txt\n",
        "\n",
        "loader = Txt(txt_path=file_path)\n",
        "doc = loader.load()\n",
        "\n",
        "doc[0:100]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "2f6baa4a0d0f3d47",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-09-01T08:49:19.381095Z",
          "start_time": "2024-09-01T08:49:18.614398Z"
        },
        "id": "2f6baa4a0d0f3d47"
      },
      "outputs": [],
      "source": [
        "# Split the loaded document into smaller chunks of text using SemanticTextSplitter\n",
        "from indoxArcg.splitter import SemanticTextSplitter\n",
        "splitter = SemanticTextSplitter(chunk_size=400)\n",
        "docs = splitter.split_text(doc)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "ad4c9ce6ab25008a",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-09-01T08:49:24.008259Z",
          "start_time": "2024-09-01T08:49:23.999623Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "ad4c9ce6ab25008a",
        "outputId": "5803f2a9-b69a-4886-f0ca-93eeb4cbf08e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"The wife of a rich man fell sick, and as she felt that her end\\nwas drawing near, she called her only daughter to her bedside and\\nsaid, dear child, be good and pious, and then the\\ngood God will always protect you, and I will look down on you\\nfrom heaven and be near you.  Thereupon she closed her eyes and\\ndeparted.  Every day the maiden went out to her mother's grave,\\nand wept, and she remained pious and good.  When winter came\\nthe snow spread a white sheet over the grave, and by the time the\\nspring sun had drawn it off again, the man had taken another wife.\\nThe woman had brought with her into the house two daughters,\\nwho were beautiful and fair of face, but vile and black of heart.\\nNow began a bad time for the poor step-child.  Is the stupid goose\\nto sit in the parlor with us, they said.  He who wants to eat bread\\nmust earn it.  Out with the kitchen-wench.  They took her pretty\\nclothes away from her, put an old grey bedgown on her, and gave\\nher wooden shoes.  Just look at the proud princess, how decked\\nout she is, they cried, and laughed, and led her into the kitchen.\\nThere she had to do hard work from morning till night, get up\\nbefore daybreak, carry water, light fires, cook and wash.  Besides\\nthis, the sisters did her every imaginable injury - they mocked her\\nand emptied her peas and lentils into the ashes, so that she was\\nforced to sit and pick them out again.  In the evening when she had\\nworked till she was weary she had no bed to go to, but had to sleep\\nby the hearth in the cinders.  And as on that account she always\\nlooked dusty and dirty, they called her cinderella.\\nIt happened that the father was once going to the fair, and he\\nasked his two step-daughters what he should bring back for them.\""
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "docs[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "4557891dec337e31",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-09-01T08:49:34.825272Z",
          "start_time": "2024-09-01T08:49:27.073881Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4557891dec337e31",
        "outputId": "0256f602-dfe0-4d0e-cfde-2356a26e7431"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m: \u001b[1mStoring documents in the vector store\u001b[0m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-03-19 02:33:00,434 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "2025-03-19 02:33:01,236 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "2025-03-19 02:33:01,423 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "2025-03-19 02:33:01,779 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "2025-03-19 02:33:02,042 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "2025-03-19 02:33:02,448 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "2025-03-19 02:33:03,005 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "2025-03-19 02:33:03,393 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "2025-03-19 02:33:03,594 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m: \u001b[1mDocument added successfully to the vector store.\u001b[0m\n",
            "\u001b[32mINFO\u001b[0m: \u001b[1mDocuments stored successfully\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "db.add(docs=docs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "VAhKGj7QBHBm",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VAhKGj7QBHBm",
        "outputId": "91b8ded8-b952-460c-e85b-b93e09b0fb15"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['_Chroma__query_collection', '_INDOX_DEFAULT_COLLECTION_NAME', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__len__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_add_documents', '_add_texts', '_client', '_client_settings', '_collection', '_embedding_function', '_persist_directory', '_similarity_search', '_similarity_search_with_score', 'add', 'delete', 'delete_collection', 'embeddings', 'get', 'override_relevance_score_fn', 'update_document', 'update_documents']\n"
          ]
        }
      ],
      "source": [
        "print(dir(db))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "I0zNzg2qAkXF",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I0zNzg2qAkXF",
        "outputId": "b3001526-d5a0-4842-9bcf-39cdf4c108fe"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['3347a135-2626-45ef-a89b-bcaab5f8f6c4',\n",
              " 'ae6521b1-4b62-46d1-b9d3-a930c2110b26',\n",
              " '26f36d00-a8bc-43d5-a132-c6fe98940566',\n",
              " '43a43db2-0d84-492d-882b-619034b56499',\n",
              " 'f95805b8-083e-4ac6-9c9d-b3ceaa4a3364',\n",
              " '402874d9-7dc6-40f8-bba0-36c50f9112e1',\n",
              " 'd3c88599-a2b1-4701-bf2c-0c87e669d8b8',\n",
              " 'ac991130-b17b-45db-8674-ea00118cc6f9',\n",
              " '7b4dba54-d3c5-4a04-99fc-d3bc733fa517']"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "db.get()['ids']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "XQd4JwSgAXYf",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XQd4JwSgAXYf",
        "outputId": "d66f336c-170f-49ed-8529-99354e663008"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"The wife of a rich man fell sick, and as she felt that her end\\nwas drawing near, she called her only daughter to her bedside and\\nsaid, dear child, be good and pious, and then the\\ngood God will always protect you, and I will look down on you\\nfrom heaven and be near you.  Thereupon she closed her eyes and\\ndeparted.  Every day the maiden went out to her mother's grave,\\nand wept, and she remained pious and good.  When winter came\\nthe snow spread a white sheet over the grave, and by the time the\\nspring sun had drawn it off again, the man had taken another wife.\\nThe woman had brought with her into the house two daughters,\\nwho were beautiful and fair of face, but vile and black of heart.\\nNow began a bad time for the poor step-child.  Is the stupid goose\\nto sit in the parlor with us, they said.  He who wants to eat bread\\nmust earn it.  Out with the kitchen-wench.  They took her pretty\\nclothes away from her, put an old grey bedgown on her, and gave\\nher wooden shoes.  Just look at the proud princess, how decked\\nout she is, they cried, and laughed, and led her into the kitchen.\\nThere she had to do hard work from morning till night, get up\\nbefore daybreak, carry water, light fires, cook and wash.  Besides\\nthis, the sisters did her every imaginable injury - they mocked her\\nand emptied her peas and lentils into the ashes, so that she was\\nforced to sit and pick them out again.  In the evening when she had\\nworked till she was weary she had no bed to go to, but had to sleep\\nby the hearth in the cinders.  And as on that account she always\\nlooked dusty and dirty, they called her cinderella.\\nIt happened that the father was once going to the fair, and he\\nasked his two step-daughters what he should bring back for them.\""
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "db.get()['documents'][0]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cd6bd4924ad116fd",
      "metadata": {
        "id": "cd6bd4924ad116fd"
      },
      "source": [
        "### Retrieve relevant information and generate an answer\n",
        "The main purpose of these lines is to perform a query on the vector store to retrieve the most relevant information (top_k=5) and generate an answer using the language model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "593ec3a85c796115",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-09-01T08:49:47.932174Z",
          "start_time": "2024-09-01T08:49:47.919102Z"
        },
        "id": "593ec3a85c796115"
      },
      "outputs": [],
      "source": [
        "from indoxArcg.pipelines.rag import RAG\n",
        "\n",
        "\n",
        "query = \"How cinderella reach her happy ending?\"\n",
        "retriever = RAG(llm=openai_qa,vector_store=db)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9e778403c8d864c4",
      "metadata": {
        "id": "9e778403c8d864c4"
      },
      "source": [
        "infer(query) method sends the query to the retriever, which searches the vector store for relevant text chunks and uses the language model to generate a response based on the retrieved information.\n",
        "Context property retrieves the context or the detailed information that the retriever used to generate the answer to the query. It provides insight into how the query was answered by showing the relevant text chunks and any additional information used."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f2c9d462",
      "metadata": {
        "id": "f2c9d462"
      },
      "source": [
        "### Basic Retrieval (just vector store lookup):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "58d79450c0807286",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-09-01T08:49:55.174402Z",
          "start_time": "2024-09-01T08:49:49.772011Z"
        },
        "id": "58d79450c0807286"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-03-19 02:34:20,574 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "2025-03-19 02:34:22,705 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        }
      ],
      "source": [
        "answer = retriever.infer(question=query,top_k=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "4a443f8a7116bd41",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-09-01T08:49:57.069903Z",
          "start_time": "2024-09-01T08:49:57.057629Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4a443f8a7116bd41",
        "outputId": "0234fcaf-1d71-4500-b29a-0c5c632f7de6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "('Cinderella reached her happy ending through a series of magical events '\n",
            " 'facilitated by a little white bird that lived in a hazel tree planted at her '\n",
            " \"mother's grave. After being mistreated by her stepmother and stepsisters, \"\n",
            " 'she expressed her wishes to the bird, which provided her with beautiful '\n",
            " \"dresses and slippers to wear to the king's festival. Despite her attempts to \"\n",
            " \"escape the king's son after each night of dancing, he devised a plan to find \"\n",
            " 'her by using a golden slipper that she left behind. When the slipper fit her '\n",
            " \"perfectly, the king's son recognized her as the beautiful maiden he had \"\n",
            " \"danced with. Ultimately, Cinderella was taken away by the king's son, and as \"\n",
            " 'they passed the hazel tree, two doves confirmed her identity, leading to her '\n",
            " 'joyful marriage and happy ending.')\n"
          ]
        }
      ],
      "source": [
        "from pprint import pprint\n",
        "pprint(answer)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "486878b3d49c9871",
      "metadata": {
        "id": "486878b3d49c9871"
      },
      "source": [
        "### Hybrid Retrieval (validates context & uses web fallback if needed):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "b64e8758",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: duckduckgo-search==4.1.1 in c:\\users\\nemat\\.conda\\envs\\markitdown\\lib\\site-packages (4.1.1)\n",
            "Requirement already satisfied: click>=8.1.7 in c:\\users\\nemat\\.conda\\envs\\markitdown\\lib\\site-packages (from duckduckgo-search==4.1.1) (8.1.8)\n",
            "Requirement already satisfied: lxml>=4.9.3 in c:\\users\\nemat\\.conda\\envs\\markitdown\\lib\\site-packages (from duckduckgo-search==4.1.1) (5.3.0)\n",
            "Requirement already satisfied: curl-cffi>=0.5.10 in c:\\users\\nemat\\.conda\\envs\\markitdown\\lib\\site-packages (from duckduckgo-search==4.1.1) (0.10.0)\n",
            "Requirement already satisfied: colorama in c:\\users\\nemat\\.conda\\envs\\markitdown\\lib\\site-packages (from click>=8.1.7->duckduckgo-search==4.1.1) (0.4.6)\n",
            "Requirement already satisfied: cffi>=1.12.0 in c:\\users\\nemat\\.conda\\envs\\markitdown\\lib\\site-packages (from curl-cffi>=0.5.10->duckduckgo-search==4.1.1) (1.17.1)\n",
            "Requirement already satisfied: certifi>=2024.2.2 in c:\\users\\nemat\\.conda\\envs\\markitdown\\lib\\site-packages (from curl-cffi>=0.5.10->duckduckgo-search==4.1.1) (2024.12.14)\n",
            "Requirement already satisfied: pycparser in c:\\users\\nemat\\.conda\\envs\\markitdown\\lib\\site-packages (from cffi>=1.12.0->curl-cffi>=0.5.10->duckduckgo-search==4.1.1) (2.22)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install duckduckgo-search==4.1.1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "f134e293",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Module imported successfully\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "import os\n",
        "\n",
        "module_path = os.path.abspath('D:/osllm/inDox/libs/indoxArcg')\n",
        "\n",
        "if module_path not in sys.path:\n",
        "    sys.path.append(module_path)\n",
        "    print(\"Module path added to sys.path\")\n",
        "\n",
        "try:\n",
        "    import indoxArcg  # Replace with the actual module name inside `indoxArcg`\n",
        "    print(\"Module imported successfully\")\n",
        "except ImportError as e:\n",
        "    print(f\"Error importing module: {e}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "8aa5b969",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pytest\n",
            "  Downloading pytest-8.3.5-py3-none-any.whl.metadata (7.6 kB)\n",
            "Requirement already satisfied: colorama in c:\\users\\nemat\\.conda\\envs\\markitdown\\lib\\site-packages (from pytest) (0.4.6)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.0rc8 in c:\\users\\nemat\\.conda\\envs\\markitdown\\lib\\site-packages (from pytest) (1.2.2)\n",
            "Collecting iniconfig (from pytest)\n",
            "  Downloading iniconfig-2.0.0-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: packaging in c:\\users\\nemat\\.conda\\envs\\markitdown\\lib\\site-packages (from pytest) (24.2)\n",
            "Collecting pluggy<2,>=1.5 (from pytest)\n",
            "  Downloading pluggy-1.5.0-py3-none-any.whl.metadata (4.8 kB)\n",
            "Requirement already satisfied: tomli>=1 in c:\\users\\nemat\\.conda\\envs\\markitdown\\lib\\site-packages (from pytest) (2.2.1)\n",
            "Downloading pytest-8.3.5-py3-none-any.whl (343 kB)\n",
            "Downloading pluggy-1.5.0-py3-none-any.whl (20 kB)\n",
            "Downloading iniconfig-2.0.0-py3-none-any.whl (5.9 kB)\n",
            "Installing collected packages: pluggy, iniconfig, pytest\n",
            "Successfully installed iniconfig-2.0.0 pluggy-1.5.0 pytest-8.3.5\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install pytest\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "85bca69e",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Content: Test Document 1, Score: 0.95\n",
            "Content: Test Document 2, Score: 0.85\n"
          ]
        }
      ],
      "source": [
        "from unittest.mock import MagicMock\n",
        "from indoxArcg.pipelines.rag.rag import StandardRetriever, RetrievalResult\n",
        "\n",
        "# Mock vector store\n",
        "vector_store = MagicMock()\n",
        "vector_store._similarity_search_with_score.return_value = [\n",
        "    (MagicMock(page_content=\"Test Document 1\"), 0.95),\n",
        "    (MagicMock(page_content=\"Test Document 2\"), 0.85),\n",
        "]\n",
        "\n",
        "# Initialize retriever\n",
        "retriever = StandardRetriever(vector_store, top_k=2)\n",
        "\n",
        "# Test retrieval\n",
        "results = retriever.retrieve(\"What is AI?\")\n",
        "\n",
        "# Display results\n",
        "for res in results:\n",
        "    print(f\"Content: {res.content}, Score: {res.score}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "59f6fd1d",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Question: What is AI?\n",
            "Answer: AI stands for Artificial Intelligence.\n"
          ]
        }
      ],
      "source": [
        "from unittest.mock import MagicMock\n",
        "from indoxArcg.pipelines.rag.rag import RAG\n",
        "\n",
        "# Mock LLM and vector store\n",
        "mock_llm = MagicMock()\n",
        "mock_vector_store = MagicMock()\n",
        "\n",
        "# Mock LLM's response\n",
        "mock_llm.answer_question.return_value = \"AI stands for Artificial Intelligence.\"\n",
        "\n",
        "# Mock vector store retrieval\n",
        "mock_vector_store._similarity_search_with_score.return_value = [\n",
        "    (MagicMock(page_content=\"AI is the simulation of human intelligence in machines.\"), 0.95)\n",
        "]\n",
        "\n",
        "# Initialize RAG\n",
        "rag = RAG(llm=mock_llm, vector_store=mock_vector_store)\n",
        "\n",
        "# Test inference\n",
        "question = \"What is AI?\"\n",
        "answer = rag.infer(question, top_k=1)\n",
        "\n",
        "print(f\"Question: {question}\")\n",
        "print(f\"Answer: {answer}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "ffefdb47",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['AnswerGenerationError',\n",
              " 'AnswerValidator',\n",
              " 'Any',\n",
              " 'BaseRetriever',\n",
              " 'ContextRetrievalError',\n",
              " 'Dict',\n",
              " 'List',\n",
              " 'MultiQueryRetriever',\n",
              " 'Optional',\n",
              " 'QueryResult',\n",
              " 'RAG',\n",
              " 'RAGError',\n",
              " 'RetrievalResult',\n",
              " 'StandardRetriever',\n",
              " 'WebSearchFallback',\n",
              " '__builtins__',\n",
              " '__cached__',\n",
              " '__doc__',\n",
              " '__file__',\n",
              " '__loader__',\n",
              " '__name__',\n",
              " '__package__',\n",
              " '__spec__',\n",
              " 'dataclass',\n",
              " 'logger',\n",
              " 'sys',\n",
              " 'warnings']"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import indoxArcg.pipelines.rag.rag as rag_module\n",
        "\n",
        "dir(rag_module)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "394533a0e6ab8228",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 801
        },
        "id": "394533a0e6ab8228",
        "outputId": "9ff4f3b1-8c25-4d6d-926e-1c865265e797"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m: \u001b[1mUsing smart retrieval\u001b[0m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-03-19 02:44:30,853 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mERROR\u001b[0m: \u001b[31m\u001b[1mError grading document: 'generator' object has no attribute 'strip'\u001b[0m\n",
            "\u001b[31mERROR\u001b[0m: \u001b[31m\u001b[1mError grading document: 'generator' object has no attribute 'strip'\u001b[0m\n",
            "\u001b[32mERROR\u001b[0m: \u001b[31m\u001b[1mSkipping this document due to an error.\u001b[0m\n",
            "\u001b[31mERROR\u001b[0m: \u001b[31m\u001b[1mSkipping this document due to an error.\u001b[0m\n",
            "\u001b[32mERROR\u001b[0m: \u001b[31m\u001b[1mError grading document: 'generator' object has no attribute 'strip'\u001b[0m\n",
            "\u001b[31mERROR\u001b[0m: \u001b[31m\u001b[1mError grading document: 'generator' object has no attribute 'strip'\u001b[0m\n",
            "\u001b[32mERROR\u001b[0m: \u001b[31m\u001b[1mSkipping this document due to an error.\u001b[0m\n",
            "\u001b[31mERROR\u001b[0m: \u001b[31m\u001b[1mSkipping this document due to an error.\u001b[0m\n",
            "\u001b[32mERROR\u001b[0m: \u001b[31m\u001b[1mError grading document: 'generator' object has no attribute 'strip'\u001b[0m\n",
            "\u001b[31mERROR\u001b[0m: \u001b[31m\u001b[1mError grading document: 'generator' object has no attribute 'strip'\u001b[0m\n",
            "\u001b[32mERROR\u001b[0m: \u001b[31m\u001b[1mSkipping this document due to an error.\u001b[0m\n",
            "\u001b[31mERROR\u001b[0m: \u001b[31m\u001b[1mSkipping this document due to an error.\u001b[0m\n",
            "\u001b[32mERROR\u001b[0m: \u001b[31m\u001b[1mError grading document: 'generator' object has no attribute 'strip'\u001b[0m\n",
            "\u001b[31mERROR\u001b[0m: \u001b[31m\u001b[1mError grading document: 'generator' object has no attribute 'strip'\u001b[0m\n",
            "\u001b[32mERROR\u001b[0m: \u001b[31m\u001b[1mSkipping this document due to an error.\u001b[0m\n",
            "\u001b[31mERROR\u001b[0m: \u001b[31m\u001b[1mSkipping this document due to an error.\u001b[0m\n",
            "\u001b[32mERROR\u001b[0m: \u001b[31m\u001b[1mError grading document: 'generator' object has no attribute 'strip'\u001b[0m\n",
            "\u001b[31mERROR\u001b[0m: \u001b[31m\u001b[1mError grading document: 'generator' object has no attribute 'strip'\u001b[0m\n",
            "\u001b[32mERROR\u001b[0m: \u001b[31m\u001b[1mSkipping this document due to an error.\u001b[0m\n",
            "\u001b[31mERROR\u001b[0m: \u001b[31m\u001b[1mSkipping this document due to an error.\u001b[0m\n",
            "\u001b[32mINFO\u001b[0m: \u001b[1mNo relevant documents found in initial context\u001b[0m\n",
            "\u001b[32mINFO\u001b[0m: \u001b[1mPerforming web search for additional context\u001b[0m\n",
            "Error in DuckDuckGo search after 5 attempts: _get_url() https://links.duckduckgo.com/d.js DuckDuckGoSearchException: Ratelimit\n",
            "\u001b[32mWARNING\u001b[0m: \u001b[33m\u001b[1mNo results from web fallback\u001b[0m\n",
            "\u001b[32mERROR\u001b[0m: \u001b[31m\u001b[1mError in RAG pipeline: No relevant context found for the question\u001b[0m\n",
            "\u001b[31mERROR\u001b[0m: \u001b[31m\u001b[1mError in RAG pipeline: No relevant context found for the question\u001b[0m\n"
          ]
        },
        {
          "ename": "AnswerGenerationError",
          "evalue": "Answer generation failed: No relevant context found for the question",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mContextRetrievalError\u001b[0m                     Traceback (most recent call last)",
            "File \u001b[1;32mD:\\osllm\\inDox\\libs\\indoxArcg\\indoxArcg\\pipelines\\rag\\rag.py:380\u001b[0m, in \u001b[0;36mRAG.infer\u001b[1;34m(self, question, top_k, use_clustering, use_multi_query, smart_retrieval)\u001b[0m\n\u001b[0;32m    379\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m context:\n\u001b[1;32m--> 380\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ContextRetrievalError(\n\u001b[0;32m    381\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo relevant context found for the question\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    382\u001b[0m     )\n\u001b[0;32m    384\u001b[0m \u001b[38;5;66;03m# Process context\u001b[39;00m\n",
            "\u001b[1;31mContextRetrievalError\u001b[0m: No relevant context found for the question",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[1;31mAnswerGenerationError\u001b[0m                     Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[26], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[43mretriever\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minfer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquestion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mwho is the next president of united states?\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtop_k\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43msmart_retrieval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mD:\\osllm\\inDox\\libs\\indoxArcg\\indoxArcg\\pipelines\\rag\\rag.py:399\u001b[0m, in \u001b[0;36mRAG.infer\u001b[1;34m(self, question, top_k, use_clustering, use_multi_query, smart_retrieval)\u001b[0m\n\u001b[0;32m    397\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    398\u001b[0m     logger\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError in RAG pipeline: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 399\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m AnswerGenerationError(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAnswer generation failed: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
            "\u001b[1;31mAnswerGenerationError\u001b[0m: Answer generation failed: No relevant context found for the question"
          ]
        }
      ],
      "source": [
        "answer = retriever.infer(\n",
        "    question=\"who is the next president of united states?\",\n",
        "    top_k=5,\n",
        "    smart_retrieval=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "d82990a0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d82990a0",
        "outputId": "99924d32-b599-4f32-c423-d9ecf5b3c6e7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "('Cinderella reached her happy ending through a series of magical events '\n",
            " 'facilitated by a little white bird that lived in a hazel tree planted at her '\n",
            " \"mother's grave. After being mistreated by her stepmother and stepsisters, \"\n",
            " 'she expressed her wishes to the bird, which provided her with beautiful '\n",
            " \"dresses and slippers to wear to the king's festival. Despite her attempts to \"\n",
            " \"escape the king's son after each night of dancing, he devised a plan to find \"\n",
            " 'her by using a golden slipper that she left behind. When the slipper fit her '\n",
            " \"perfectly, the king's son recognized her as the beautiful maiden he had \"\n",
            " \"danced with. Ultimately, Cinderella was taken away by the king's son, and as \"\n",
            " 'they passed the hazel tree, two doves confirmed her identity, leading to her '\n",
            " 'joyful marriage and happy ending.')\n"
          ]
        }
      ],
      "source": [
        "from pprint import pprint\n",
        "pprint(answer)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eada6d75",
      "metadata": {
        "id": "eada6d75"
      },
      "source": [
        "### Advanced Retrieval (with multi-query):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b34430f8",
      "metadata": {
        "id": "b34430f8",
        "outputId": "2eaf2901-45d1-47ea-d470-d4942b836533"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m: \u001b[1mMulti-query retrieval initialized\u001b[0m\n",
            "\u001b[32mINFO\u001b[0m: \u001b[1mRunning multi-query retrieval for: How cinderella reach her happy ending?\u001b[0m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-01-20 19:58:30,157 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m: \u001b[1mGenerated queries: ['Here are three different queries you can use to gather information about how Cinderella reaches her happy ending:', '1. **Query for Fairy Tale Summary**:', '- \"What are the key events in the story of Cinderella that lead to her happy ending?\"', '2. **Query for Character Development**:', '- \"How do Cinderella\\'s character traits and actions contribute to her achieving a happy ending in the fairy tale?\"', '3. **Query for Themes and Motifs**:', '- \"What themes and motifs in the Cinderella story illustrate how she ultimately reaches her happy ending?\"']\u001b[0m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-01-20 19:58:31,752 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "2025-01-20 19:58:33,101 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "2025-01-20 19:58:33,900 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "2025-01-20 19:58:35,280 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "2025-01-20 19:58:36,455 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "2025-01-20 19:58:37,464 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "2025-01-20 19:58:39,111 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m: \u001b[1mRetrieved 35 relevant passages\u001b[0m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-01-20 19:58:49,616 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO\u001b[0m: \u001b[1mGenerated final response\u001b[0m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-01-20 19:58:55,239 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        }
      ],
      "source": [
        "answer = retriever.infer(\n",
        "    question=query,\n",
        "    top_k=5,\n",
        "    use_clustering=False,\n",
        "    use_multi_query=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d64a79a4",
      "metadata": {
        "id": "d64a79a4",
        "outputId": "ab7ef63b-6117-4a19-875c-6b8d45103a3a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "('Cinderella reaches her happy ending through a combination of her unwavering '\n",
            " 'goodness, perseverance, and the magical assistance she receives from her '\n",
            " \"mother's spirit, symbolized by the hazel tree and the little bird. After \"\n",
            " \"planting a hazel branch on her mother's grave and weeping over it, a magical \"\n",
            " 'tree grows, which becomes a source of comfort and help for her. Whenever she '\n",
            " 'expresses a wish beneath the tree, the little white bird grants her those '\n",
            " 'wishes, providing her with beautiful dresses and shoes that allow her to '\n",
            " \"attend the royal festival despite her stepmother's attempts to keep her from \"\n",
            " 'going.\\n'\n",
            " '\\n'\n",
            " 'At the festival, Cinderella captures the attention of the prince, who dances '\n",
            " 'only with her. However, she must leave quickly each time, leaving behind a '\n",
            " 'golden slipper on the staircase. The prince then searches for the owner of '\n",
            " 'the slipper, declaring he will marry the girl whose foot fits it. While her '\n",
            " 'stepsisters attempt to fit into the slipper by cutting off parts of their '\n",
            " 'feet, they are ultimately revealed as false brides by the doves at the hazel '\n",
            " 'tree.\\n'\n",
            " '\\n'\n",
            " 'When Cinderella tries on the slipper, it fits perfectly, and the prince '\n",
            " 'recognizes her as the beautiful maiden he danced with. As they pass the '\n",
            " 'hazel tree, the doves confirm her identity, leading to her marriage with the '\n",
            " \"prince. In the end, Cinderella's kindness and resilience are rewarded, while \"\n",
            " 'her stepsisters face punishment for their cruelty. Thus, through love, '\n",
            " 'magic, and her virtuous nature, Cinderella achieves her happy ending.')\n"
          ]
        }
      ],
      "source": [
        "from pprint import pprint\n",
        "pprint(answer)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d7df916f",
      "metadata": {
        "id": "d7df916f"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "MarkitDown",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}

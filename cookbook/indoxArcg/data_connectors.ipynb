{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e94fa46dec8845f",
   "metadata": {},
   "source": [
    "# Document\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6bd003340b908701",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-20T09:19:05.050471Z",
     "start_time": "2024-08-20T09:19:05.034424Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document ID: 1b4c4c46d9824485a3f7b8b136575b59\n",
      "Source: Wikipedia\n",
      "Content: Wikipedia is a free online encyclopedia.\n",
      "Metadata: {'language': 'English', 'accessed_date': '2024-08-20'}\n",
      "Document as dictionary: {'doc_id': '1b4c4c46d9824485a3f7b8b136575b59', 'source': 'Wikipedia', 'content': 'Wikipedia is a free online encyclopedia.', 'metadata': {'language': 'English', 'accessed_date': '2024-08-20'}}\n",
      "New document: Doc ID: 1b4c4c46d9824485a3f7b8b136575b59\n",
      "Source: Wikipedia\n",
      "Content: Wikipedia is a free online encyclopedia.\n",
      "\n",
      "Doc ID: 1b4c4c46d9824485a3f7b8b136575b59\n",
      "Source: Wikipedia\n",
      "Content: Wikipedia is a free online encyclopedia.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from indoxArcg.data_connectors import Document\n",
    "\n",
    "# Create a new document\n",
    "doc = Document(\n",
    "    source=\"Wikipedia\",\n",
    "    content=\"Wikipedia is a free online encyclopedia.\",\n",
    "    metadata={\"language\": \"English\", \"accessed_date\": \"2024-08-20\"}\n",
    ")\n",
    "\n",
    "# Access document attributes\n",
    "print(f\"Document ID: {doc.id_}\")\n",
    "print(f\"Source: {doc.source}\")\n",
    "print(f\"Content: {doc.content}\")\n",
    "print(f\"Metadata: {doc.metadata}\")\n",
    "\n",
    "# Convert to dictionary\n",
    "doc_dict = doc.to_dict()\n",
    "print(\"Document as dictionary:\", doc_dict)\n",
    "\n",
    "# Create a new document from dictionary\n",
    "new_doc = Document.from_dict(doc_dict)\n",
    "print(\"New document:\", new_doc)\n",
    "\n",
    "# String representation\n",
    "print(str(doc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aed0a93241d76da0",
   "metadata": {},
   "source": [
    "# Wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5996b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "58abaf8044733728",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-21T07:50:21.432950Z",
     "start_time": "2024-08-21T07:50:20.152097Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Python (programming language)\n",
      "URL: https://en.wikipedia.org/wiki/Python_(programming_language)\n",
      "Summary: Python is a high-level, general-purpose programming language. Its design philosophy emphasizes code readability with the use of significant indentation.\n",
      "Python is dynamically typed and garbage-collect...\n",
      "Content preview: Python is a high-level, general-purpose programming language. Its design philosophy emphasizes code readability with the use of significant indentation.\n",
      "Python is dynamically typed and garbage-collect...\n",
      "---\n",
      "Title: Artificial intelligence\n",
      "URL: https://en.wikipedia.org/wiki/Artificial_intelligence\n",
      "Summary: Artificial intelligence (AI), in its broadest sense, is intelligence exhibited by machines, particularly computer systems. It is a field of research in computer science that develops and studies metho...\n",
      "Content preview: Artificial intelligence (AI), in its broadest sense, is intelligence exhibited by machines, particularly computer systems. It is a field of research in computer science that develops and studies metho...\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "from indoxArcg.data_connectors import WikipediaReader\n",
    "\n",
    "# Initialize the reader\n",
    "reader = WikipediaReader()\n",
    "\n",
    "# Fetch content from specific Wikipedia pages\n",
    "pages = [\"Python (programming language)\", \"Artificial intelligence\"]\n",
    "documents = reader.load_data(pages=pages)\n",
    "\n",
    "# Process the retrieved documents\n",
    "for doc in documents:\n",
    "    print(f\"Title: {doc.metadata['title']}\")\n",
    "    print(f\"URL: {doc.metadata['url']}\")\n",
    "    print(f\"Summary: {doc.metadata['summary'][:200]}...\")\n",
    "    print(f\"Content preview: {doc.content[:200]}...\")\n",
    "    print(\"---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "650815a16fc156ac",
   "metadata": {},
   "source": [
    "# YouTube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f4e79e0a3171a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install youtube_transcript_api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18402c6c2b5bb6d5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-20T08:23:38.741264Z",
     "start_time": "2024-08-20T08:23:33.055549Z"
    }
   },
   "outputs": [],
   "source": [
    "from indoxArcg.data_connectors import YoutubeTranscriptReader\n",
    "\n",
    "# Initialize the reader\n",
    "reader = YoutubeTranscriptReader()\n",
    "\n",
    "# Fetch transcripts from specific YouTube videos\n",
    "video_links = [\"https://www.youtube.com/watch?v=dN0lsF2cvm4&t=44s\"]\n",
    "documents = reader.load_data(ytlinks=video_links)\n",
    "\n",
    "# Process the retrieved documents\n",
    "for doc in documents:\n",
    "    print(f\"Video ID: {doc.metadata['video_id']}\")\n",
    "    print(f\"Video Link: {doc.metadata['link']}\")\n",
    "    print(f\"Language: {doc.metadata['language']}\")\n",
    "    print(f\"Transcript preview: {doc.content[:200]}...\")\n",
    "    print(\"---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44591962e5a3c9b6",
   "metadata": {},
   "source": [
    "# Arxiv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "57f294d7dbbc421b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-20T07:24:52.272530Z",
     "start_time": "2024-08-20T07:24:49.958168Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: LaMDA: Language Models for Dialog Applications\n",
      "Authors: Romal Thoppilan, Daniel De Freitas, Jamie Hall, Noam Shazeer, Apoorv Kulshreshtha, Heng-Tze Cheng, Alicia Jin, Taylor Bos, Leslie Baker, Yu Du, YaGuang Li, Hongrae Lee, Huaixiu Steven Zheng, Amin Ghafouri, Marcelo Menegali, Yanping Huang, Maxim Krikun, Dmitry Lepikhin, James Qin, Dehao Chen, Yuanzhong Xu, Zhifeng Chen, Adam Roberts, Maarten Bosma, Vincent Zhao, Yanqi Zhou, Chung-Ching Chang, Igor Krivokon, Will Rusch, Marc Pickett, Pranesh Srinivasan, Laichee Man, Kathleen Meier-Hellstern, Meredith Ringel Morris, Tulsee Doshi, Renelito Delos Santos, Toju Duke, Johnny Soraker, Ben Zevenbergen, Vinodkumar Prabhakaran, Mark Diaz, Ben Hutchinson, Kristen Olson, Alejandra Molina, Erin Hoffman-John, Josh Lee, Lora Aroyo, Ravi Rajakumar, Alena Butryna, Matthew Lamm, Viktoriya Kuzmina, Joe Fenton, Aaron Cohen, Rachel Bernstein, Ray Kurzweil, Blaise Aguera-Arcas, Claire Cui, Marian Croak, Ed Chi, Quoc Le\n",
      "Abstract: Title: LaMDA: Language Models for Dialog Applications\n",
      "\n",
      "Authors: Romal Thoppilan, Daniel De Freitas, Jamie Hall, Noam Shazeer, Apoorv Kulshreshtha, Heng-Tze Cheng, Alicia Jin, Taylor Bos, Leslie Baker,...\n",
      "arXiv URL: http://arxiv.org/abs/2201.08239v3\n",
      "---\n",
      "Title: Training language models to follow instructions with human feedback\n",
      "Authors: Long Ouyang, Jeff Wu, Xu Jiang, Diogo Almeida, Carroll L. Wainwright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, John Schulman, Jacob Hilton, Fraser Kelton, Luke Miller, Maddie Simens, Amanda Askell, Peter Welinder, Paul Christiano, Jan Leike, Ryan Lowe\n",
      "Abstract: Title: Training language models to follow instructions with human feedback\n",
      "\n",
      "Authors: Long Ouyang, Jeff Wu, Xu Jiang, Diogo Almeida, Carroll L. Wainwright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal...\n",
      "arXiv URL: http://arxiv.org/abs/2203.02155v1\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "from indoxArcg.data_connectors import ArxivReader\n",
    "\n",
    "reader = ArxivReader()\n",
    "\n",
    "paper_ids = [\"2201.08239\", \"2203.02155\"]\n",
    "documents = reader.load_data(paper_ids)\n",
    "\n",
    "for doc in documents:\n",
    "    print(f\"Title: {doc.metadata['title']}\")\n",
    "    print(f\"Authors: {doc.metadata['authors']}\")\n",
    "    print(f\"Abstract: {doc.content[:200]}...\") \n",
    "    print(f\"arXiv URL: {doc.metadata['arxiv_url']}\")\n",
    "    print(\"---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "16f4e6e85ac7f81e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-20T07:21:48.745761Z",
     "start_time": "2024-08-20T07:21:48.734015Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'paper_id': '2201.08239', 'title': 'LaMDA: Language Models for Dialog Applications', 'authors': 'Romal Thoppilan, Daniel De Freitas, Jamie Hall, Noam Shazeer, Apoorv Kulshreshtha, Heng-Tze Cheng, Alicia Jin, Taylor Bos, Leslie Baker, Yu Du, YaGuang Li, Hongrae Lee, Huaixiu Steven Zheng, Amin Ghafouri, Marcelo Menegali, Yanping Huang, Maxim Krikun, Dmitry Lepikhin, James Qin, Dehao Chen, Yuanzhong Xu, Zhifeng Chen, Adam Roberts, Maarten Bosma, Vincent Zhao, Yanqi Zhou, Chung-Ching Chang, Igor Krivokon, Will Rusch, Marc Pickett, Pranesh Srinivasan, Laichee Man, Kathleen Meier-Hellstern, Meredith Ringel Morris, Tulsee Doshi, Renelito Delos Santos, Toju Duke, Johnny Soraker, Ben Zevenbergen, Vinodkumar Prabhakaran, Mark Diaz, Ben Hutchinson, Kristen Olson, Alejandra Molina, Erin Hoffman-John, Josh Lee, Lora Aroyo, Ravi Rajakumar, Alena Butryna, Matthew Lamm, Viktoriya Kuzmina, Joe Fenton, Aaron Cohen, Rachel Bernstein, Ray Kurzweil, Blaise Aguera-Arcas, Claire Cui, Marian Croak, Ed Chi, Quoc Le', 'published': datetime.datetime(2022, 1, 20, 15, 44, 37, tzinfo=datetime.timezone.utc), 'arxiv_url': 'http://arxiv.org/abs/2201.08239v3'}\n"
     ]
    }
   ],
   "source": [
    "print(documents[0].metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d153ea3c21cb007b",
   "metadata": {},
   "source": [
    "# Twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f15ded72465093",
   "metadata": {},
   "outputs": [],
   "source": [
    "from indoxArcg.data_connectors import TwitterTweetReader\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "# Initialize the reader with your bearer token\n",
    "twitter_token = os.environ['twitter_token']\n",
    "reader = TwitterTweetReader(bearer_token=twitter_token)\n",
    "\n",
    "# Fetch tweets from specific Twitter handles\n",
    "twitter_handles = [\"OpenAI\", \"DeepMind\"]\n",
    "documents = reader.load_data(twitterhandles=twitter_handles, num_tweets=50)\n",
    "\n",
    "# Process the retrieved documents\n",
    "for doc in documents:\n",
    "    print(f\"Username: {doc.metadata['username']}\")\n",
    "    print(f\"User ID: {doc.metadata['user_id']}\")\n",
    "    print(f\"Number of tweets: {doc.metadata['num_tweets']}\")\n",
    "    print(f\"Tweets preview: {doc.content[:200]}...\")\n",
    "    print(\"---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10194d6d3bd27319",
   "metadata": {},
   "source": [
    "# GutenBerg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a94d2b4515d33",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-20T07:52:03.790599Z",
     "start_time": "2024-08-20T07:52:01.770559Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Unknown Title\n",
      "Content preview: ï»¿ï»¿*** START OF THE PROJECT GUTENBERG EBOOK ALICE'S ADVENTURES IN\r\n",
      "WONDERLAND ***\r\n",
      "[Illustration]\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "Aliceâs Adventures in Wonderland\r\n",
      "\r\n",
      "by Lewis Carroll\r\n",
      "\r\n",
      "THE MILLENNIUM FULCRUM EDITION 3...\n",
      "---\n",
      "Book ID: 1661\n",
      "Title: The Adventures of Sherlock Holmes\n",
      "Author: Arthur Conan Doyle\n",
      "---\n",
      "Book ID: 244\n",
      "Title: A Study in Scarlet\n",
      "Author: Arthur Conan Doyle\n",
      "---\n",
      "Book ID: 2852\n",
      "Title: The Hound of the Baskervilles\n",
      "Author: Arthur Conan Doyle\n",
      "---\n",
      "Book ID: 2097\n",
      "Title: The Sign of the Four\n",
      "Author: Arthur Conan Doyle\n",
      "---\n",
      "Book ID: 834\n",
      "Title: The Memoirs of Sherlock Holmes\n",
      "Author: Arthur Conan Doyle\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "from indoxArcg.data_connectors import GutenbergReader\n",
    "\n",
    "# Initialize the reader\n",
    "reader = GutenbergReader()\n",
    "\n",
    "# Fetch a specific book by ID\n",
    "book_id = \"11\"  # Alice's Adventures in Wonderland\n",
    "book = reader.get_book(book_id)\n",
    "\n",
    "if book:\n",
    "    print(f\"Title: {book.metadata['title']}\")\n",
    "    print(f\"Content preview: {book.content[:200]}...\")\n",
    "    print(\"---\")\n",
    "\n",
    "# Search for books\n",
    "search_query = \"Sherlock Holmes\"\n",
    "search_results = reader.search_gutenberg(search_query)\n",
    "\n",
    "for result in search_results[:5]:  # Print first 5 results\n",
    "    print(f\"Book ID: {result.metadata['book_id']}\")\n",
    "    print(f\"Title: {result.metadata['title']}\")\n",
    "    print(f\"Author: {result.metadata['author']}\")\n",
    "    print(\"---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76888f0ad2a1ec0c",
   "metadata": {},
   "source": [
    "# Github"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c1bd3c37a0350b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-20T07:32:27.275468Z",
     "start_time": "2024-08-20T07:32:08.506953Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: Branch_and_PR_Guidelines.md\n",
      "Processing file: README.md\n",
      "Processing file: docs/metrics/AnswerRelevancy.md\n",
      "Processing file: docs/metrics/BLEU.md\n",
      "Processing file: docs/metrics/Bertscore.md\n",
      "Processing file: docs/metrics/Bias.md\n",
      "Processing file: docs/metrics/ContextualRelevancy.md\n",
      "Processing file: docs/metrics/Fairness.md\n",
      "Processing file: docs/metrics/Faithfulness.md\n",
      "Processing file: docs/metrics/GEval.md\n",
      "Processing file: docs/metrics/Gruen.md\n",
      "Processing file: docs/metrics/Hallucination.md\n",
      "Processing file: docs/metrics/Harmfulness.md\n",
      "Processing file: docs/metrics/KnowledgeRetention.md\n",
      "Processing file: docs/metrics/METEOR.md\n",
      "Processing file: docs/metrics/MachineEthics.md\n",
      "Processing file: docs/metrics/Misinformation.md\n",
      "Processing file: docs/metrics/Privacy.md\n",
      "Processing file: docs/metrics/ROUGE.md\n",
      "Processing file: docs/metrics/Stereotype and Bias.md\n",
      "Processing file: docs/metrics/Toxicity.md\n",
      "Processing file: docs/piplines/CustomEvaluator.md\n",
      "Processing file: docs/piplines/LLMComparison.md\n",
      "Processing file: docs/piplines/LLMEvaluator.md\n",
      "Processing file: docs/piplines/RagEvaluator.md\n",
      "Processing file: docs/piplines/SafetyEvaluator.md\n",
      "File: Branch_and_PR_Guidelines.md\n",
      "Path: Branch_and_PR_Guidelines.md\n",
      "Size: 1725 bytes\n",
      "Content preview: # Branch Naming and Pull Request Guidelines for the Team\n",
      "\n",
      "### Note 1: Branch Naming\n",
      "\n",
      "Pay attention to the type of task assigned to you. Is it a feature, a bug, or a refactor?\n",
      "\n",
      "- If it's a bug: The bra...\n",
      "---\n",
      "File: README.md\n",
      "Path: README.md\n",
      "Size: 10406 bytes\n",
      "Content preview: <p align=\"center\">\n",
      "\n",
      "\n",
      "<div style=\"position: relative; width: 100%; text-align: center;\">\n",
      "    <h1>inDoxJudge</h1>\n",
      "    <a href=\"https://github.com/osllmai/inDoxJudge\">\n",
      "<img src=\"https://readme-typing-svg...\n",
      "---\n",
      "File: AnswerRelevancy.md\n",
      "Path: docs/metrics/AnswerRelevancy.md\n",
      "Size: 3714 bytes\n",
      "Content preview: # AnswerRelevancy\n",
      "\n",
      "Class for evaluating the relevancy of language model outputs by analyzing statements, generating verdicts, and calculating relevancy scores.\n",
      "\n",
      "## Initialization\n",
      "\n",
      "The `AnswerRelevancy...\n",
      "---\n",
      "File: BLEU.md\n",
      "Path: docs/metrics/BLEU.md\n",
      "Size: 2395 bytes\n",
      "Content preview: # BLEU\n",
      "\n",
      "Class for evaluating the similarity between a generated response and one or more expected responses using the BLEU metric, which is based on n-gram overlaps.\n",
      "\n",
      "## Initialization\n",
      "\n",
      "The `BLEU` cla...\n",
      "---\n",
      "File: Bertscore.md\n",
      "Path: docs/metrics/Bertscore.md\n",
      "Size: 2631 bytes\n",
      "Content preview: # BertScore\n",
      "\n",
      "Class for evaluating the similarity between a generated response and one or more expected responses using embeddings from a pre-trained transformer model.\n",
      "\n",
      "## Initialization\n",
      "\n",
      "The `BertSco...\n",
      "---\n",
      "File: Bias.md\n",
      "Path: docs/metrics/Bias.md\n",
      "Size: 2858 bytes\n",
      "Content preview: # Bias\n",
      "\n",
      "Class for evaluating potential bias in language model outputs by analyzing opinions, generating verdicts, and calculating bias scores.\n",
      "\n",
      "## Initialization\n",
      "\n",
      "The `Bias` class is initialized with ...\n",
      "---\n",
      "File: ContextualRelevancy.md\n",
      "Path: docs/metrics/ContextualRelevancy.md\n",
      "Size: 2004 bytes\n",
      "Content preview: # ContextualRelevancy\n",
      "\n",
      "Class for evaluating the contextual relevancy of retrieval contexts based on a given query using a specified language model.\n",
      "\n",
      "## Initialization\n",
      "\n",
      "The `ContextualRelevancy` class ...\n",
      "---\n",
      "File: Fairness.md\n",
      "Path: docs/metrics/Fairness.md\n",
      "Size: 1753 bytes\n",
      "Content preview: \n",
      "# Fairness\n",
      "\n",
      "Class for evaluating the fairness of language model outputs by analyzing the fairness score, reasons, and verdicts using a specified language model.\n",
      "\n",
      "## Initialization\n",
      "\n",
      "The `Fairness` cla...\n",
      "---\n",
      "File: Faithfulness.md\n",
      "Path: docs/metrics/Faithfulness.md\n",
      "Size: 2077 bytes\n",
      "Content preview: # Faithfulness\n",
      "\n",
      "Class for evaluating the faithfulness of language model outputs by analyzing claims, truths, verdicts, and reasons using a specified language model.\n",
      "\n",
      "## Initialization\n",
      "\n",
      "The `Faithfulne...\n",
      "---\n",
      "File: GEval.md\n",
      "Path: docs/metrics/GEval.md\n",
      "Size: 4851 bytes\n",
      "Content preview: # GEval\n",
      "\n",
      "Class for evaluating various aspects of language model outputs, including retrieval quality, integration, coherence, relevance, accuracy, fluency, comprehensiveness, and contextuality.\n",
      "\n",
      "## In...\n",
      "---\n",
      "File: Gruen.md\n",
      "Path: docs/metrics/Gruen.md\n",
      "Size: 1473 bytes\n",
      "Content preview: # Gruen\n",
      "\n",
      "Class for evaluating the quality of generated text using various metrics, including grammaticality, redundancy, and focus.\n",
      "\n",
      "## Initialization\n",
      "\n",
      "The `Gruen` class is initialized with the follow...\n",
      "---\n",
      "File: Hallucination.md\n",
      "Path: docs/metrics/Hallucination.md\n",
      "Size: 3641 bytes\n",
      "Content preview: # Hallucination\n",
      "\n",
      "Class for evaluating hallucinations in language model outputs by analyzing the generated responses, generating verdicts, and calculating hallucination scores.\n",
      "\n",
      "## Initialization\n",
      "\n",
      "The ...\n",
      "---\n",
      "File: Harmfulness.md\n",
      "Path: docs/metrics/Harmfulness.md\n",
      "Size: 1932 bytes\n",
      "Content preview: \n",
      "---\n",
      "\n",
      "# Harmfulness\n",
      "\n",
      "Class for evaluating the potential harmfulness of language model outputs by analyzing the input sentence and generating harmfulness scores, reasons, and verdicts using a specified...\n",
      "---\n",
      "File: KnowledgeRetention.md\n",
      "Path: docs/metrics/KnowledgeRetention.md\n",
      "Size: 3541 bytes\n",
      "Content preview: # KnowledgeRetention\n",
      "\n",
      "Class for evaluating the retention of knowledge in language model outputs by analyzing the continuity of knowledge across multiple messages, generating verdicts, and calculating ...\n",
      "---\n",
      "File: METEOR.md\n",
      "Path: docs/metrics/METEOR.md\n",
      "Size: 1782 bytes\n",
      "Content preview: # METEOR\n",
      "\n",
      "Class for evaluating the similarity between a generated response and one or more reference contexts using the METEOR metric, which considers precision, recall, and fragmentation.\n",
      "\n",
      "## Initial...\n",
      "---\n",
      "File: MachineEthics.md\n",
      "Path: docs/metrics/MachineEthics.md\n",
      "Size: 1875 bytes\n",
      "Content preview: # Machine Ethics\n",
      "\n",
      "Class for evaluating the ethical implications of language model outputs by analyzing input sentences and generating verdicts, reasons, and ethical scores using a specified language m...\n",
      "---\n",
      "File: Misinformation.md\n",
      "Path: docs/metrics/Misinformation.md\n",
      "Size: 1958 bytes\n",
      "Content preview: # Misinformation\n",
      "\n",
      "Class for evaluating the presence of misinformation in an input sentence by analyzing the sentence using a specified language model. It generates a verdict and reasons based on the i...\n",
      "---\n",
      "File: Privacy.md\n",
      "Path: docs/metrics/Privacy.md\n",
      "Size: 1757 bytes\n",
      "Content preview: # Privacy\n",
      "\n",
      "Class for evaluating privacy-related concerns in language model outputs by analyzing input sentences, generating reasons, and determining verdicts using a specified model.\n",
      "\n",
      "## Initializatio...\n",
      "---\n",
      "File: ROUGE.md\n",
      "Path: docs/metrics/ROUGE.md\n",
      "Size: 1788 bytes\n",
      "Content preview: # Rouge\n",
      "\n",
      "Class for evaluating the similarity between a generated response and one or more expected responses using the ROUGE metric, which considers n-gram overlaps for recall and precision.\n",
      "\n",
      "## Initi...\n",
      "---\n",
      "File: Stereotype and Bias.md\n",
      "Path: docs/metrics/Stereotype and Bias.md\n",
      "Size: 1944 bytes\n",
      "Content preview: # StereotypeBias\n",
      "\n",
      "Class for evaluating the stereotype and bias in language model outputs by analyzing the input sentence, generating reasons, and providing verdicts using a specified language model.\n",
      "\n",
      "...\n",
      "---\n",
      "File: Toxicity.md\n",
      "Path: docs/metrics/Toxicity.md\n",
      "Size: 3349 bytes\n",
      "Content preview: # Toxicity\n",
      "\n",
      "Class for evaluating toxicity in language model outputs by analyzing opinions, generating verdicts, and calculating toxicity scores.\n",
      "\n",
      "## Initialization\n",
      "\n",
      "The `Toxicity` class is initialized...\n",
      "---\n",
      "File: CustomEvaluator.md\n",
      "Path: docs/piplines/CustomEvaluator.md\n",
      "Size: 3987 bytes\n",
      "Content preview: # CustomEvaluator\n",
      "\n",
      "## Overview\n",
      "\n",
      "The `CustomEvaluator` class is designed to evaluate various aspects of language model outputs using a range of metrics. It\n",
      "supports metrics such as Faithfulness, Answer...\n",
      "---\n",
      "File: LLMComparison.md\n",
      "Path: docs/piplines/LLMComparison.md\n",
      "Size: 2882 bytes\n",
      "Content preview: # LLMComparison\n",
      "\n",
      "## Overview\n",
      "\n",
      "The `LLMComparison` class is designed to facilitate the comparison of multiple language models based on their evaluation metrics. This class allows for visual representat...\n",
      "---\n",
      "File: LLMEvaluator.md\n",
      "Path: docs/piplines/LLMEvaluator.md\n",
      "Size: 5161 bytes\n",
      "Content preview: # LLMEvaluator\n",
      "\n",
      "## Overview\n",
      "\n",
      "The `LLMEvaluator` class is designed to evaluate various aspects of language model outputs using specified metrics. It supports metrics such as Faithfulness, Answer Releva...\n",
      "---\n",
      "File: RagEvaluator.md\n",
      "Path: docs/piplines/RagEvaluator.md\n",
      "Size: 4662 bytes\n",
      "Content preview: # RagEvaluator\n",
      "\n",
      "## Overview\n",
      "\n",
      "The `RagEvaluator` class is designed to evaluate various aspects of language model outputs in the context of Retrieval-Augmented Generation (RAG) using specified metrics. ...\n",
      "---\n",
      "File: SafetyEvaluator.md\n",
      "Path: docs/piplines/SafetyEvaluator.md\n",
      "Size: 2657 bytes\n",
      "Content preview: \n",
      "---\n",
      "\n",
      "# SafetyEvaluator\n",
      "\n",
      "## Overview\n",
      "\n",
      "The `SafetyEvaluator` class is designed to assess various safety-related aspects of a given input using a set of predefined metrics. This class includes metrics s...\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "from indoxArcg.data_connectors import GithubClient, GithubRepositoryReader\n",
    "from dotenv import load_dotenv\n",
    "import os \n",
    "\n",
    "load_dotenv('api.env')\n",
    "github_token = os.environ['github_token']\n",
    "github_client = GithubClient(github_token=github_token)\n",
    "\n",
    "# Instantiate the repository reader\n",
    "repo_reader = GithubRepositoryReader(\n",
    "    github_client=github_client,\n",
    "    owner=\"osllmai\",\n",
    "    repo=\"indoxjudge\",\n",
    "    filter_directories=([\"docs\"], GithubRepositoryReader.FilterType.INCLUDE),\n",
    "    filter_file_extensions=([\".md\"], GithubRepositoryReader.FilterType.INCLUDE)\n",
    ")\n",
    "\n",
    "# Load data from the repository\n",
    "documents = repo_reader.load_data(branch=\"main\")\n",
    "\n",
    "# Print document information\n",
    "for doc in documents:\n",
    "    print(f\"File: {doc.metadata['file_name']}\")\n",
    "    print(f\"Path: {doc.metadata['file_path']}\")\n",
    "    print(f\"Size: {doc.metadata['file_size']} bytes\")\n",
    "    print(f\"Content preview: {doc.content[:200]}...\")\n",
    "    print(\"---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35001ae224a7d7a5",
   "metadata": {},
   "source": [
    "# Discord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e7b102cff7a724a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-20T13:37:37.268545Z",
     "start_time": "2024-08-20T13:37:30.425623Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-08-20 17:07:31] [INFO    ] discord.client: logging in using static token\n",
      "[2024-08-20 17:07:34] [INFO    ] discord.gateway: Shard ID None has connected to Gateway (Session ID: 92edb3a8acf6df38664b999619ee7edd).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channel ID: 1275046109722447915\n",
      "Channel Name: general\n",
      "Number of messages: 2\n",
      "Messages preview: \n",
      "Hi this a test...\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "from indoxArcg.data_connectors import DiscordChannelReader\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import nest_asyncio\n",
    "\n",
    "# Apply the nest_asyncio patch\n",
    "nest_asyncio.apply()\n",
    "\n",
    "load_dotenv('api.env')\n",
    "# Initialize the reader with your bearer token\n",
    "discord_token = os.environ['discord_token']\n",
    "reader = DiscordChannelReader(bot_token=discord_token)\n",
    "\n",
    "# Fetch messages from specific Discord channels\n",
    "channel_ids = [1275046109722447915]\n",
    "documents = reader.load_data(channel_ids=channel_ids, num_messages=50)\n",
    "\n",
    "# Process the retrieved documents\n",
    "for doc in documents:\n",
    "    print(f\"Channel ID: {doc.metadata['channel_id']}\")\n",
    "    print(f\"Channel Name: {doc.metadata['channel_name']}\")\n",
    "    print(f\"Number of messages: {doc.metadata['num_messages']}\")\n",
    "    print(f\"Messages preview: {doc.content[:200]}...\")\n",
    "    print(\"---\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

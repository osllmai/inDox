# Hallucination

Class for evaluating hallucinations in language model outputs by analyzing the generated responses, generating verdicts, and calculating hallucination scores.

## Initialization

The `Hallucination` class is initialized with the following parameters:

- **llm_response**: The response generated by the language model.
- **retrieval_context**: The context from which information was retrieved for comparison.
- **threshold**: The threshold for determining hallucinations. Defaults to `0.5`.
- **include_reason**: Whether to include reasoning for the hallucination verdicts. Defaults to `True`.
- **strict_mode**: Whether to use strict mode, which forces a score of 1 if hallucination exceeds the threshold. Defaults to `False`.

```python
class Hallucination:
    """
    Class for evaluating hallucinations in language model outputs by analyzing the generated responses,
    generating verdicts, and calculating hallucination scores.
    """
    def __init__(self, llm_response: str, retrieval_context: str, threshold: float = 0.5, include_reason: bool = True,
                 strict_mode: bool = False):
        """
        Initializes the Hallucination class with the LLM response, retrieval context, and evaluation settings.

        Parameters:
        llm_response (str): The response generated by the language model.
        retrieval_context (str): The context from which information was retrieved for comparison.
        threshold (float): The threshold for determining hallucinations. Defaults to 0.5.
        include_reason (bool): Whether to include reasoning for the hallucination verdicts. Defaults to True.
        strict_mode (bool): Whether to use strict mode, which forces a score of 1 if hallucination exceeds the threshold. Defaults to False.
        """
```
# Hyperparameters Explanation

- **llm_response**: A string containing the response from the language model that is being evaluated for hallucinations.

- **retrieval_context**: A string containing the context or reference information used to verify the accuracy of the language model's output.

- **threshold**: A float value representing the hallucination threshold. If the hallucination score exceeds this threshold, the output may be flagged as a hallucination. The default value is 0.5.

- **include_reason**: A boolean indicating whether the evaluation should include detailed reasons for the hallucination verdict. Default is True.

- **strict_mode**: A boolean that, when set to True, forces a score of 1 if the hallucination exceeds the threshold, regardless of the exact score. This is useful for stringent hallucination detection. Default is False.

# Usage Example

Here is an example of how to use the `Hallucination` class:

```python
import os
from dotenv import load_dotenv
from indox.IndoxEval.llms import OpenAi
from indox.IndoxEval import Hallucination, Evaluator

load_dotenv()
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

# Initialize the language model
llm = OpenAi(api_key=OPENAI_API_KEY, model="gpt-3.5-turbo")

# Define the response and retrieval context to be evaluated
llm_response = "The Eiffel Tower is located in Berlin."
retrieval_context = "The Eiffel Tower is located in Paris, France."

# Initialize the Hallucination evaluation metric
hallucination_metric = Hallucination(
    llm_response=llm_response, 
    retrieval_context=retrieval_context, 
    threshold=0.5, 
    include_reason=True, 
    strict_mode=False
)

# Create an evaluator with the Hallucination metric
evaluator = Evaluator(model=llm, metrics=[hallucination_metric])
result = evaluator.evaluate()
```
